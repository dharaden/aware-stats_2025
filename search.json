[
  {
    "objectID": "slides/desc-viz.html#describe",
    "href": "slides/desc-viz.html#describe",
    "title": "Describe & Vizualize",
    "section": "describe()",
    "text": "describe()\nThis function automatically calculates all of the descriptives we reviewed above (and more!). Use the describe() function from the psych package on the entire dataset.\nNotes: If you load a library at the beginning, you can directly call any function from it. Instead, you can call a function by library_name::function_name without loading the entire library.\n\npsych::describe(tipi)\n\n                    vars  n    mean       sd median trimmed    mad    min\nid                     1 99 1058.12    31.05 1059.0 1057.93  38.55 1006.0\nprogress               2 99  100.00     0.00  100.0  100.00   0.00  100.0\nduration_in_seconds    3 99 7197.29 34904.64 1461.0 1527.88 486.29  623.0\nconsent                4 99    1.00     0.00    1.0    1.00   0.00    1.0\ngenderid               5 99    4.46     0.82    4.0    4.47   1.48    1.0\ngenderid_7_text*       6 99    1.03     0.22    1.0    1.00   0.00    1.0\nsex                    7 99    1.51     0.50    2.0    1.51   0.00    1.0\nage                    8 99   19.78     1.84   20.0   19.53   1.48   17.0\nyear_school            9 99    2.18     1.22    2.0    2.04   1.48    1.0\nq85                   10 99    1.64     1.32    1.0    1.32   0.00    1.0\nq85_6_text*           11 99    1.03     0.22    1.0    1.00   0.00    1.0\ntipi_1                12 99    3.99     1.90    4.0    3.99   2.97    1.0\ntipi_2                13 99    4.15     1.53    4.0    4.23   1.48    1.0\ntipi_3                14 99    5.38     1.26    6.0    5.51   1.48    1.0\ntipi_4                15 99    4.29     1.69    5.0    4.31   1.48    1.0\ntipi_5                16 99    5.38     1.28    6.0    5.52   1.48    1.0\ntipi_6                17 99    4.76     1.64    5.0    4.84   1.48    1.0\ntipi_7                18 99    5.45     1.24    6.0    5.57   1.48    2.0\ntipi_8                19 99    3.17     1.70    3.0    3.09   1.48    1.0\ntipi_9                20 99    5.01     1.35    5.0    5.05   1.48    2.0\ntipi_10               21 99    3.10     1.48    3.0    3.04   1.48    1.0\nsleep_quality         22 99    2.56     1.15    2.0    2.46   1.48    1.0\nhours_of_sleep        23 99    6.51     1.04    7.0    6.63   0.00    1.0\ntipi_2r               24 99    3.85     1.53    4.0    3.77   1.48    1.0\ntipi_4r               25 99    3.71     1.69    3.0    3.69   1.48    1.0\ntipi_6r               26 99    3.24     1.64    3.0    3.16   1.48    1.0\ntipi_8r               27 99    4.83     1.70    5.0    4.91   1.48    1.0\ntipi_10r              28 99    4.90     1.48    5.0    4.96   1.48    1.0\nextra                 29 99    3.62     1.60    3.5    3.56   2.22    1.0\nagree                 30 99    4.65     1.08    4.5    4.63   0.74    2.0\nconsc                 31 99    5.11     1.22    5.5    5.15   1.48    2.0\nemo                   32 99    4.36     1.29    4.5    4.37   1.48    1.5\nopen                  33 99    5.14     1.04    5.0    5.19   0.74    2.5\n                       max    range  skew kurtosis      se\nid                    1112    106.0  0.03    -1.21    3.12\nprogress               100      0.0   NaN      NaN    0.00\nduration_in_seconds 252521 251898.0  6.57    42.24 3508.05\nconsent                  1      0.0   NaN      NaN    0.00\ngenderid                 7      6.0 -0.81     5.57    0.08\ngenderid_7_text*         3      2.0  7.70    61.15    0.02\nsex                      2      1.0 -0.02    -2.02    0.05\nage                     31     14.0  2.67    12.52    0.19\nyear_school              5      4.0  0.73    -0.44    0.12\nq85                      7      6.0  2.18     4.14    0.13\nq85_6_text*              3      2.0  7.70    61.15    0.02\ntipi_1                   7      6.0  0.01    -1.34    0.19\ntipi_2                   7      6.0 -0.46    -0.58    0.15\ntipi_3                   7      6.0 -0.86     0.58    0.13\ntipi_4                   7      6.0 -0.17    -0.95    0.17\ntipi_5                   7      6.0 -0.94     0.86    0.13\ntipi_6                   7      6.0 -0.46    -0.86    0.17\ntipi_7                   7      5.0 -0.65    -0.08    0.12\ntipi_8                   7      6.0  0.37    -1.12    0.17\ntipi_9                   7      5.0 -0.29    -0.81    0.14\ntipi_10                  7      6.0  0.35    -0.71    0.15\nsleep_quality            5      4.0  0.87     0.14    0.12\nhours_of_sleep           8      7.0 -2.01     5.99    0.10\ntipi_2r                  7      6.0  0.46    -0.58    0.15\ntipi_4r                  7      6.0  0.17    -0.95    0.17\ntipi_6r                  7      6.0  0.46    -0.86    0.17\ntipi_8r                  7      6.0 -0.37    -1.12    0.17\ntipi_10r                 7      6.0 -0.35    -0.71    0.15\nextra                    7      6.0  0.18    -0.98    0.16\nagree                    7      5.0  0.11     0.04    0.11\nconsc                    7      5.0 -0.32    -0.70    0.12\nemo                      7      5.5 -0.10    -0.54    0.13\nopen                     7      4.5 -0.48     0.13    0.10\n\n# or if you have already loaded the library\n\ndescribe(tipi)\n\n                    vars  n    mean       sd median trimmed    mad    min\nid                     1 99 1058.12    31.05 1059.0 1057.93  38.55 1006.0\nprogress               2 99  100.00     0.00  100.0  100.00   0.00  100.0\nduration_in_seconds    3 99 7197.29 34904.64 1461.0 1527.88 486.29  623.0\nconsent                4 99    1.00     0.00    1.0    1.00   0.00    1.0\ngenderid               5 99    4.46     0.82    4.0    4.47   1.48    1.0\ngenderid_7_text*       6 99    1.03     0.22    1.0    1.00   0.00    1.0\nsex                    7 99    1.51     0.50    2.0    1.51   0.00    1.0\nage                    8 99   19.78     1.84   20.0   19.53   1.48   17.0\nyear_school            9 99    2.18     1.22    2.0    2.04   1.48    1.0\nq85                   10 99    1.64     1.32    1.0    1.32   0.00    1.0\nq85_6_text*           11 99    1.03     0.22    1.0    1.00   0.00    1.0\ntipi_1                12 99    3.99     1.90    4.0    3.99   2.97    1.0\ntipi_2                13 99    4.15     1.53    4.0    4.23   1.48    1.0\ntipi_3                14 99    5.38     1.26    6.0    5.51   1.48    1.0\ntipi_4                15 99    4.29     1.69    5.0    4.31   1.48    1.0\ntipi_5                16 99    5.38     1.28    6.0    5.52   1.48    1.0\ntipi_6                17 99    4.76     1.64    5.0    4.84   1.48    1.0\ntipi_7                18 99    5.45     1.24    6.0    5.57   1.48    2.0\ntipi_8                19 99    3.17     1.70    3.0    3.09   1.48    1.0\ntipi_9                20 99    5.01     1.35    5.0    5.05   1.48    2.0\ntipi_10               21 99    3.10     1.48    3.0    3.04   1.48    1.0\nsleep_quality         22 99    2.56     1.15    2.0    2.46   1.48    1.0\nhours_of_sleep        23 99    6.51     1.04    7.0    6.63   0.00    1.0\ntipi_2r               24 99    3.85     1.53    4.0    3.77   1.48    1.0\ntipi_4r               25 99    3.71     1.69    3.0    3.69   1.48    1.0\ntipi_6r               26 99    3.24     1.64    3.0    3.16   1.48    1.0\ntipi_8r               27 99    4.83     1.70    5.0    4.91   1.48    1.0\ntipi_10r              28 99    4.90     1.48    5.0    4.96   1.48    1.0\nextra                 29 99    3.62     1.60    3.5    3.56   2.22    1.0\nagree                 30 99    4.65     1.08    4.5    4.63   0.74    2.0\nconsc                 31 99    5.11     1.22    5.5    5.15   1.48    2.0\nemo                   32 99    4.36     1.29    4.5    4.37   1.48    1.5\nopen                  33 99    5.14     1.04    5.0    5.19   0.74    2.5\n                       max    range  skew kurtosis      se\nid                    1112    106.0  0.03    -1.21    3.12\nprogress               100      0.0   NaN      NaN    0.00\nduration_in_seconds 252521 251898.0  6.57    42.24 3508.05\nconsent                  1      0.0   NaN      NaN    0.00\ngenderid                 7      6.0 -0.81     5.57    0.08\ngenderid_7_text*         3      2.0  7.70    61.15    0.02\nsex                      2      1.0 -0.02    -2.02    0.05\nage                     31     14.0  2.67    12.52    0.19\nyear_school              5      4.0  0.73    -0.44    0.12\nq85                      7      6.0  2.18     4.14    0.13\nq85_6_text*              3      2.0  7.70    61.15    0.02\ntipi_1                   7      6.0  0.01    -1.34    0.19\ntipi_2                   7      6.0 -0.46    -0.58    0.15\ntipi_3                   7      6.0 -0.86     0.58    0.13\ntipi_4                   7      6.0 -0.17    -0.95    0.17\ntipi_5                   7      6.0 -0.94     0.86    0.13\ntipi_6                   7      6.0 -0.46    -0.86    0.17\ntipi_7                   7      5.0 -0.65    -0.08    0.12\ntipi_8                   7      6.0  0.37    -1.12    0.17\ntipi_9                   7      5.0 -0.29    -0.81    0.14\ntipi_10                  7      6.0  0.35    -0.71    0.15\nsleep_quality            5      4.0  0.87     0.14    0.12\nhours_of_sleep           8      7.0 -2.01     5.99    0.10\ntipi_2r                  7      6.0  0.46    -0.58    0.15\ntipi_4r                  7      6.0  0.17    -0.95    0.17\ntipi_6r                  7      6.0  0.46    -0.86    0.17\ntipi_8r                  7      6.0 -0.37    -1.12    0.17\ntipi_10r                 7      6.0 -0.35    -0.71    0.15\nextra                    7      6.0  0.18    -0.98    0.16\nagree                    7      5.0  0.11     0.04    0.11\nconsc                    7      5.0 -0.32    -0.70    0.12\nemo                      7      5.5 -0.10    -0.54    0.13\nopen                     7      4.5 -0.48     0.13    0.10\n\n\nNOTE: Some variables are not numeric and are categorical variables of type character. By default, the describe() function forces non-numeric variables to be numeric and attempts to calculate descriptives for them. These variables are marked with an asterisk (*). In this case, it doesn’t make sense to calculate descriptive statistics for these variables, so we get a warning message and a bunch of NaN’s and NA’s for these variables.\nA better approach would be to remove non-numeric variables before you attempt to run numerical calculations on your dataset."
  },
  {
    "objectID": "slides/desc-viz.html#make-it-pretty",
    "href": "slides/desc-viz.html#make-it-pretty",
    "title": "Describe & Vizualize",
    "section": "Make it Pretty",
    "text": "Make it Pretty\nUsing sjPlot (https://strengejacke.github.io/sjPlot/index.html) we can make things a little more publishable! You can use select() to also keep particular variables (maybe you don’t care about the skew)\n\ntipi %&gt;% \n  psych::describe() %&gt;% \n  sjPlot::tab_df()\n\n\n\n\nvars\nn\nmean\nsd\nmedian\ntrimmed\nmad\nmin\nmax\nrange\nskew\nkurtosis\nse\n\n\n1\n99\n1058.12\n31.05\n1059.00\n1057.93\n38.55\n1006.00\n1112\n106.00\n0.03\n-1.21\n3.12\n\n\n2\n99\n100.00\n0.00\n100.00\n100.00\n0.00\n100.00\n100\n0.00\nNaN\nNaN\n0.00\n\n\n3\n99\n7197.29\n34904.64\n1461.00\n1527.88\n486.29\n623.00\n252521\n251898.00\n6.57\n42.24\n3508.05\n\n\n4\n99\n1.00\n0.00\n1.00\n1.00\n0.00\n1.00\n1\n0.00\nNaN\nNaN\n0.00\n\n\n5\n99\n4.46\n0.82\n4.00\n4.47\n1.48\n1.00\n7\n6.00\n-0.81\n5.57\n0.08\n\n\n6\n99\n1.03\n0.22\n1.00\n1.00\n0.00\n1.00\n3\n2.00\n7.70\n61.15\n0.02\n\n\n7\n99\n1.51\n0.50\n2.00\n1.51\n0.00\n1.00\n2\n1.00\n-0.02\n-2.02\n0.05\n\n\n8\n99\n19.78\n1.84\n20.00\n19.53\n1.48\n17.00\n31\n14.00\n2.67\n12.52\n0.19\n\n\n9\n99\n2.18\n1.22\n2.00\n2.04\n1.48\n1.00\n5\n4.00\n0.73\n-0.44\n0.12\n\n\n10\n99\n1.64\n1.32\n1.00\n1.32\n0.00\n1.00\n7\n6.00\n2.18\n4.14\n0.13\n\n\n11\n99\n1.03\n0.22\n1.00\n1.00\n0.00\n1.00\n3\n2.00\n7.70\n61.15\n0.02\n\n\n12\n99\n3.99\n1.90\n4.00\n3.99\n2.97\n1.00\n7\n6.00\n0.01\n-1.34\n0.19\n\n\n13\n99\n4.15\n1.53\n4.00\n4.23\n1.48\n1.00\n7\n6.00\n-0.46\n-0.58\n0.15\n\n\n14\n99\n5.38\n1.26\n6.00\n5.51\n1.48\n1.00\n7\n6.00\n-0.86\n0.58\n0.13\n\n\n15\n99\n4.29\n1.69\n5.00\n4.31\n1.48\n1.00\n7\n6.00\n-0.17\n-0.95\n0.17\n\n\n16\n99\n5.38\n1.28\n6.00\n5.52\n1.48\n1.00\n7\n6.00\n-0.94\n0.86\n0.13\n\n\n17\n99\n4.76\n1.64\n5.00\n4.84\n1.48\n1.00\n7\n6.00\n-0.46\n-0.86\n0.17\n\n\n18\n99\n5.45\n1.24\n6.00\n5.57\n1.48\n2.00\n7\n5.00\n-0.65\n-0.08\n0.12\n\n\n19\n99\n3.17\n1.70\n3.00\n3.09\n1.48\n1.00\n7\n6.00\n0.37\n-1.12\n0.17\n\n\n20\n99\n5.01\n1.35\n5.00\n5.05\n1.48\n2.00\n7\n5.00\n-0.29\n-0.81\n0.14\n\n\n21\n99\n3.10\n1.48\n3.00\n3.04\n1.48\n1.00\n7\n6.00\n0.35\n-0.71\n0.15\n\n\n22\n99\n2.56\n1.15\n2.00\n2.46\n1.48\n1.00\n5\n4.00\n0.87\n0.14\n0.12\n\n\n23\n99\n6.51\n1.04\n7.00\n6.63\n0.00\n1.00\n8\n7.00\n-2.01\n5.99\n0.10\n\n\n24\n99\n3.85\n1.53\n4.00\n3.77\n1.48\n1.00\n7\n6.00\n0.46\n-0.58\n0.15\n\n\n25\n99\n3.71\n1.69\n3.00\n3.69\n1.48\n1.00\n7\n6.00\n0.17\n-0.95\n0.17\n\n\n26\n99\n3.24\n1.64\n3.00\n3.16\n1.48\n1.00\n7\n6.00\n0.46\n-0.86\n0.17\n\n\n27\n99\n4.83\n1.70\n5.00\n4.91\n1.48\n1.00\n7\n6.00\n-0.37\n-1.12\n0.17\n\n\n28\n99\n4.90\n1.48\n5.00\n4.96\n1.48\n1.00\n7\n6.00\n-0.35\n-0.71\n0.15\n\n\n29\n99\n3.62\n1.60\n3.50\n3.56\n2.22\n1.00\n7\n6.00\n0.18\n-0.98\n0.16\n\n\n30\n99\n4.65\n1.08\n4.50\n4.63\n0.74\n2.00\n7\n5.00\n0.11\n0.04\n0.11\n\n\n31\n99\n5.11\n1.22\n5.50\n5.15\n1.48\n2.00\n7\n5.00\n-0.32\n-0.70\n0.12\n\n\n32\n99\n4.36\n1.29\n4.50\n4.37\n1.48\n1.50\n7\n5.50\n-0.10\n-0.54\n0.13\n\n\n33\n99\n5.14\n1.04\n5.00\n5.19\n0.74\n2.50\n7\n4.50\n-0.48\n0.13\n0.10"
  },
  {
    "objectID": "slides/desc-viz.html#ggplot2-from-the-tidyverse",
    "href": "slides/desc-viz.html#ggplot2-from-the-tidyverse",
    "title": "Describe & Vizualize",
    "section": "ggplot2 from the tidyverse",
    "text": "ggplot2 from the tidyverse\nSince we have already installed and loaded the library, we don’t have to do anything else at this point!\nggplot2 follows the “grammar of graphics”\n\nTheoretical framework for creating data visualizations\nBreaks the process down into separate components:\n\n\n\nData\nAesthetics (aes)\nGeometric Objects (geoms)\n\nFaceting\nThemes"
  },
  {
    "objectID": "slides/desc-viz.html#grammar-of-graphics",
    "href": "slides/desc-viz.html#grammar-of-graphics",
    "title": "Describe & Vizualize",
    "section": "Grammar of Graphics",
    "text": "Grammar of Graphics"
  },
  {
    "objectID": "slides/desc-viz.html#ggplot2-syntax",
    "href": "slides/desc-viz.html#ggplot2-syntax",
    "title": "Describe & Vizualize",
    "section": "ggplot2 syntax",
    "text": "ggplot2 syntax\nThere is a basic structure to create a plot within ggplot2, and consists of at least these three things:\n\nA Data Set\nCoordinate System\nGeoms - visual marks to represent the data points\n\nIn R it looks like this:\n\nggplot(data = &lt;DATA&gt;) + \n  &lt;GEOM_FUNCTION&gt;(mapping = aes(&lt;MAPPINGS&gt;))\n\n#or how I like to do it\n&lt;DATA&gt; %&gt;% \n  ggplot(aes(&lt;MAPPINGS&gt;)) + \n  &lt;GEOM_FUNCTION&gt;()"
  },
  {
    "objectID": "slides/desc-viz.html#ggplot2-syntax-1",
    "href": "slides/desc-viz.html#ggplot2-syntax-1",
    "title": "Describe & Vizualize",
    "section": "ggplot2 syntax",
    "text": "ggplot2 syntax\nLet’s start with a basic figure with our TIPI data\nFirst we will define the data that we are using and the variables we are visualizing\n\n#the dataset is called penguins\n\ntipi %&gt;% \n  #including the variables we want to visualize\n  ggplot(aes(x = emo, \n             y = extra))\n\nWhat happens?"
  },
  {
    "objectID": "slides/desc-viz.html#adding-in-color",
    "href": "slides/desc-viz.html#adding-in-color",
    "title": "Describe & Vizualize",
    "section": "Adding in Color",
    "text": "Adding in Color\nMaybe we would like to have each of the points colored by their respective sex\nThis information will be added to the aes() within the geom_point() layer\n\ntipi %&gt;% \n  ggplot(aes(x = emo, \n             y = extra)) + \n  geom_point(aes(color=sex))"
  },
  {
    "objectID": "slides/desc-viz.html#including-a-fit-line",
    "href": "slides/desc-viz.html#including-a-fit-line",
    "title": "Describe & Vizualize",
    "section": "Including a fit line",
    "text": "Including a fit line\nWhy don’t we put in a line that represents the relationship between these variables?\nWe will want to add another layer/geom\n\ntipi %&gt;% \n  ggplot(aes(x = emo, \n             y = extra)) + \n  geom_point(aes(color=sex)) + \n  geom_smooth()\n\n\nThat looks a little wonky…why is that? Did you get a note in the console?"
  },
  {
    "objectID": "slides/desc-viz.html#including-a-fit-line-1",
    "href": "slides/desc-viz.html#including-a-fit-line-1",
    "title": "Describe & Vizualize",
    "section": "Including a fit line",
    "text": "Including a fit line\nThe geom_smooth() defaults to using a loess line to fit to the data\nIn order to update that, we need to change some of the defaults for that layer and specify that we want a “linear model” or lm function to the data\n\ntipi %&gt;% \n  ggplot(aes(x = emo, \n             y = extra)) + \n  geom_point(aes(color=sex)) + \n  geom_smooth(method = 'lm')\n\n\nDid that look a little better?"
  },
  {
    "objectID": "slides/desc-viz.html#individual-fit-lines",
    "href": "slides/desc-viz.html#individual-fit-lines",
    "title": "Describe & Vizualize",
    "section": "Individual fit lines",
    "text": "Individual fit lines\nIt might make more sense to have individual lines for each of the species instead of something that is across all\n\ntipi %&gt;% \n  ggplot(aes(x = emo, \n             y = extra, \n             color = sex)) + \n  geom_point(aes(color=sex)) + \n  geom_smooth(method = 'lm')\n\n\nWhat did we move around from the last set of code?\nWhat was the error you got?"
  },
  {
    "objectID": "slides/desc-viz.html#data-types",
    "href": "slides/desc-viz.html#data-types",
    "title": "Describe & Vizualize",
    "section": "Data Types",
    "text": "Data Types\nIt looks like R is looking at our binary variable as a continuous number\nWe want to be able to tell our code that these are categories/factors\nIf we want to change or compute a new variable, what do we use?\n\n\ntipi &lt;- tipi %&gt;% \n  mutate(sex = as.factor(sex))"
  },
  {
    "objectID": "slides/desc-viz.html#updating-labelstitle",
    "href": "slides/desc-viz.html#updating-labelstitle",
    "title": "Describe & Vizualize",
    "section": "Updating Labels/Title",
    "text": "Updating Labels/Title\nIt will default to including the variable names as the x and y labels, but that isn’t something that makes sense. Also would be good to have a title!\nWe add on another layer called labs() for our labels (link)\n\ntipi %&gt;% \n  ggplot(aes(x = emo, \n             y = extra, \n             color = sex)) + \n  geom_point(aes(color=sex)) + \n  geom_smooth(method = 'lm') + \n  labs(\n    title = \"TIPI Data\",\n    subtitle = \"Extraversion by Emotional Stability\", \n    x = \"motional Stability\", \n    y = \"Extraversion\", \n    color = \"Sex at Birth\"\n  )"
  },
  {
    "objectID": "slides/desc-viz.html#other-graphs",
    "href": "slides/desc-viz.html#other-graphs",
    "title": "Describe & Vizualize",
    "section": "Other Graphs",
    "text": "Other Graphs\nTake another look at the ggplot cheatsheet\nWhat else is a useful chart?"
  },
  {
    "objectID": "slides/topic-1.html#replication-reproducibility-1",
    "href": "slides/topic-1.html#replication-reproducibility-1",
    "title": "Getting Started!",
    "section": "Replication & Reproducibility 🍰",
    "text": "Replication & Reproducibility 🍰\nI want to bake a cake!\n\nFind a recipe online (try ignoring their life story narrative)\nGet ingredients (Wegmans if you 💰)\nFollow recipe and bake 🧑‍🍳\nEnjoy the delicious cake 🍽️\n\n\nReplication"
  },
  {
    "objectID": "slides/topic-1.html#replication-reproducibility-2",
    "href": "slides/topic-1.html#replication-reproducibility-2",
    "title": "Getting Started!",
    "section": "Replication & Reproducibility 🍰",
    "text": "Replication & Reproducibility 🍰\nI want to bake a cake!\nReproduction\n\nFind a recipe online –&gt; Find their kitchen\nGet ingredients –&gt; Use their ingredients\nFollow recipe and bake –&gt; Watch what they do and follow\nEnjoy the delicious cake –&gt; Enjoy cake (and jail for B&E)"
  },
  {
    "objectID": "slides/topic-1.html#replication-reproducibility-3",
    "href": "slides/topic-1.html#replication-reproducibility-3",
    "title": "Getting Started!",
    "section": "Replication & Reproducibility 📊",
    "text": "Replication & Reproducibility 📊\n\n\n\n\n\n\n\n\nReplication\nReproducibility\n\n\n\n\nHave a similar research question\nUse the same research question\n\n\nCollect your own data\nUse their data\n\n\nFollow their steps with your resources\nFollow their steps with their resources\n\n\nOutcome: Similar results (depends on other factors)\nOutcome: Identical results"
  },
  {
    "objectID": "slides/topic-1.html#replication-reproducibility-4",
    "href": "slides/topic-1.html#replication-reproducibility-4",
    "title": "Getting Started!",
    "section": "Replication & Reproducibility 📊",
    "text": "Replication & Reproducibility 📊\nGoals of Science\nImportant: We want to replicate other researchers work\nMOST Important: Be able to reproduce all of our results\nYou are your own worst collaborator!"
  },
  {
    "objectID": "slides/topic-1.html#garden-of-forking-paths",
    "href": "slides/topic-1.html#garden-of-forking-paths",
    "title": "Getting Started!",
    "section": "Garden of Forking Paths",
    "text": "Garden of Forking Paths"
  },
  {
    "objectID": "slides/topic-1.html#installing-and-using-r",
    "href": "slides/topic-1.html#installing-and-using-r",
    "title": "Getting Started!",
    "section": "Installing and Using R",
    "text": "Installing and Using R\nFrom the course website\nModern Statistics Using R"
  },
  {
    "objectID": "slides/topic-1.html#working-with-r-studio",
    "href": "slides/topic-1.html#working-with-r-studio",
    "title": "Getting Started!",
    "section": "Working with R-Studio",
    "text": "Working with R-Studio\nR-Studio is just like a kitchen 🧑‍🍳\nThe Environment pane is the pantry/fridge\nThe Console is like the oven/stove\nThe Markdown document is the recipe\nThe bottom right sometimes acts as the little window on the oven where you can see things baking\nCreating a Project puts these things in their place & Establishes your working directory"
  },
  {
    "objectID": "slides/topic-1.html#getting-started-in-r-studio",
    "href": "slides/topic-1.html#getting-started-in-r-studio",
    "title": "Getting Started!",
    "section": "Getting Started in R-Studio",
    "text": "Getting Started in R-Studio\n\nStart with a Blank Slate\nMake the code work for you\nThis is your space - make it look the way you want"
  },
  {
    "objectID": "slides/topic-1.html#next-steps",
    "href": "slides/topic-1.html#next-steps",
    "title": "Getting Started!",
    "section": "Next Steps",
    "text": "Next Steps\n\nCreate a project\nSet up a Markdown Document\nRun and Knit the document\n\n\n\n\n\n\n\nNote\n\n\nThis is a reminder to Dr Haraden to talk to everyone about keyboard shortcuts."
  },
  {
    "objectID": "slides/template-seasons.html#quarto",
    "href": "slides/template-seasons.html#quarto",
    "title": "AI-PROWIL IRES 2025 - Statistics Workshop",
    "section": "Quarto",
    "text": "Quarto\nQuarto enables you to weave together content and executable code into a finished presentation. To learn more about Quarto presentations see https://quarto.org/docs/presentations/."
  },
  {
    "objectID": "slides/template-seasons.html#bullets",
    "href": "slides/template-seasons.html#bullets",
    "title": "AI-PROWIL IRES 2025 - Statistics Workshop",
    "section": "Bullets",
    "text": "Bullets\nWhen you click the Render button a document will be generated that includes:\n\nContent authored with markdown\nOutput from executable code\n\n\nlm(mpg ~ disp, data = mtcars)\n\n\nCall:\nlm(formula = mpg ~ disp, data = mtcars)\n\nCoefficients:\n(Intercept)         disp  \n   29.59985     -0.04122"
  },
  {
    "objectID": "slides/template-seasons.html#latex-equations",
    "href": "slides/template-seasons.html#latex-equations",
    "title": "AI-PROWIL IRES 2025 - Statistics Workshop",
    "section": "LaTeX Equations",
    "text": "LaTeX Equations\nMathJax rendering of equations to HTML\n\\[\\begin{gather*}\na_1=b_1+c_1\\\\\na_2=b_2+c_2-d_2+e_2\n\\end{gather*}\\]\n\\[\\begin{align}\na_{11}& =b_{11}&\n  a_{12}& =b_{12}\\\\\na_{21}& =b_{21}&\n  a_{22}& =b_{22}+c_{22}\n\\end{align}\\]"
  },
  {
    "objectID": "slides/template-seasons.html#tables",
    "href": "slides/template-seasons.html#tables",
    "title": "AI-PROWIL IRES 2025 - Statistics Workshop",
    "section": "Tables",
    "text": "Tables\n\n\n\nSyntax\nDescription\n\n\n\n\nHeader\nTitle\n\n\nParagraph\nText"
  },
  {
    "objectID": "slides/template-seasons.html#callout-blocks",
    "href": "slides/template-seasons.html#callout-blocks",
    "title": "AI-PROWIL IRES 2025 - Statistics Workshop",
    "section": "Callout Blocks",
    "text": "Callout Blocks\n\n\n\n\n\n\nNote\n\n\nNote that there are five types of callouts, including: note, warning, important, tip, and caution.\n\n\n\n\n\n\n\n\n\nImportant\n\n\nDanger, callouts will really improve your writing.\n\n\n\n\n\n\n\n\n\nTip With Caption\n\n\nThis is an example of a callout with a caption."
  },
  {
    "objectID": "slides/template-seasons.html#quarto-1",
    "href": "slides/template-seasons.html#quarto-1",
    "title": "AI-PROWIL IRES 2025 - Statistics Workshop",
    "section": "Quarto",
    "text": "Quarto\nQuarto enables you to weave together content and executable code into a finished presentation. To learn more about Quarto presentations see https://quarto.org/docs/presentations/."
  },
  {
    "objectID": "slides/template-seasons.html#bullets-1",
    "href": "slides/template-seasons.html#bullets-1",
    "title": "AI-PROWIL IRES 2025 - Statistics Workshop",
    "section": "Bullets",
    "text": "Bullets\nWhen you click the Render button a document will be generated that includes:\n\nContent authored with markdown\nOutput from executable code\n\n\nlm(mpg ~ disp, data = mtcars)\n\n\nCall:\nlm(formula = mpg ~ disp, data = mtcars)\n\nCoefficients:\n(Intercept)         disp  \n   29.59985     -0.04122"
  },
  {
    "objectID": "slides/template-seasons.html#latex-equations-1",
    "href": "slides/template-seasons.html#latex-equations-1",
    "title": "AI-PROWIL IRES 2025 - Statistics Workshop",
    "section": "LaTeX Equations",
    "text": "LaTeX Equations\nMathJax rendering of equations to HTML\n\\[\\begin{gather*}\na_1=b_1+c_1\\\\\na_2=b_2+c_2-d_2+e_2\n\\end{gather*}\\]\n\\[\\begin{align}\na_{11}& =b_{11}&\n  a_{12}& =b_{12}\\\\\na_{21}& =b_{21}&\n  a_{22}& =b_{22}+c_{22}\n\\end{align}\\]"
  },
  {
    "objectID": "slides/template-seasons.html#tables-1",
    "href": "slides/template-seasons.html#tables-1",
    "title": "AI-PROWIL IRES 2025 - Statistics Workshop",
    "section": "Tables",
    "text": "Tables\n\n\n\nSyntax\nDescription\n\n\n\n\nHeader\nTitle\n\n\nParagraph\nText"
  },
  {
    "objectID": "slides/template-seasons.html#callout-blocks-1",
    "href": "slides/template-seasons.html#callout-blocks-1",
    "title": "AI-PROWIL IRES 2025 - Statistics Workshop",
    "section": "Callout Blocks",
    "text": "Callout Blocks\n\n\n\n\n\n\nNote\n\n\nNote that there are five types of callouts, including: note, warning, important, tip, and caution.\n\n\n\n\n\n\n\n\n\nImportant\n\n\nDanger, callouts will really improve your writing.\n\n\n\n\n\n\n\n\n\nTip With Caption\n\n\nThis is an example of a callout with a caption."
  },
  {
    "objectID": "slides/template-seasons.html#quarto-2",
    "href": "slides/template-seasons.html#quarto-2",
    "title": "AI-PROWIL IRES 2025 - Statistics Workshop",
    "section": "Quarto",
    "text": "Quarto\nQuarto enables you to weave together content and executable code into a finished presentation. To learn more about Quarto presentations see https://quarto.org/docs/presentations/."
  },
  {
    "objectID": "slides/template-seasons.html#bullets-2",
    "href": "slides/template-seasons.html#bullets-2",
    "title": "AI-PROWIL IRES 2025 - Statistics Workshop",
    "section": "Bullets",
    "text": "Bullets\nWhen you click the Render button a document will be generated that includes:\n\nContent authored with markdown\nOutput from executable code\n\n\nlm(mpg ~ disp, data = mtcars)\n\n\nCall:\nlm(formula = mpg ~ disp, data = mtcars)\n\nCoefficients:\n(Intercept)         disp  \n   29.59985     -0.04122"
  },
  {
    "objectID": "slides/template-seasons.html#latex-equations-2",
    "href": "slides/template-seasons.html#latex-equations-2",
    "title": "AI-PROWIL IRES 2025 - Statistics Workshop",
    "section": "LaTeX Equations",
    "text": "LaTeX Equations\nMathJax rendering of equations to HTML\n\\[\\begin{gather*}\na_1=b_1+c_1\\\\\na_2=b_2+c_2-d_2+e_2\n\\end{gather*}\\]\n\\[\\begin{align}\na_{11}& =b_{11}&\n  a_{12}& =b_{12}\\\\\na_{21}& =b_{21}&\n  a_{22}& =b_{22}+c_{22}\n\\end{align}\\]"
  },
  {
    "objectID": "slides/template-seasons.html#tables-2",
    "href": "slides/template-seasons.html#tables-2",
    "title": "AI-PROWIL IRES 2025 - Statistics Workshop",
    "section": "Tables",
    "text": "Tables\n\n\n\nSyntax\nDescription\n\n\n\n\nHeader\nTitle\n\n\nParagraph\nText"
  },
  {
    "objectID": "slides/template-seasons.html#callout-blocks-2",
    "href": "slides/template-seasons.html#callout-blocks-2",
    "title": "AI-PROWIL IRES 2025 - Statistics Workshop",
    "section": "Callout Blocks",
    "text": "Callout Blocks\n\n\n\n\n\n\nNote\n\n\nNote that there are five types of callouts, including: note, warning, important, tip, and caution.\n\n\n\n\n\n\n\n\n\nImportant\n\n\nDanger, callouts will really improve your writing.\n\n\n\n\n\n\n\n\n\nTip With Caption\n\n\nThis is an example of a callout with a caption."
  },
  {
    "objectID": "slides/template-seasons.html#quarto-3",
    "href": "slides/template-seasons.html#quarto-3",
    "title": "AI-PROWIL IRES 2025 - Statistics Workshop",
    "section": "Quarto",
    "text": "Quarto\nQuarto enables you to weave together content and executable code into a finished presentation. To learn more about Quarto presentations see https://quarto.org/docs/presentations/."
  },
  {
    "objectID": "slides/template-seasons.html#bullets-3",
    "href": "slides/template-seasons.html#bullets-3",
    "title": "AI-PROWIL IRES 2025 - Statistics Workshop",
    "section": "Bullets",
    "text": "Bullets\nWhen you click the Render button a document will be generated that includes:\n\nContent authored with markdown\nOutput from executable code\n\n\nlm(mpg ~ disp, data = mtcars)\n\n\nCall:\nlm(formula = mpg ~ disp, data = mtcars)\n\nCoefficients:\n(Intercept)         disp  \n   29.59985     -0.04122"
  },
  {
    "objectID": "slides/template-seasons.html#latex-equations-3",
    "href": "slides/template-seasons.html#latex-equations-3",
    "title": "AI-PROWIL IRES 2025 - Statistics Workshop",
    "section": "LaTeX Equations",
    "text": "LaTeX Equations\nMathJax rendering of equations to HTML\n\\[\\begin{gather*}\na_1=b_1+c_1\\\\\na_2=b_2+c_2-d_2+e_2\n\\end{gather*}\\]\n\\[\\begin{align}\na_{11}& =b_{11}&\n  a_{12}& =b_{12}\\\\\na_{21}& =b_{21}&\n  a_{22}& =b_{22}+c_{22}\n\\end{align}\\]"
  },
  {
    "objectID": "slides/template-seasons.html#tables-3",
    "href": "slides/template-seasons.html#tables-3",
    "title": "AI-PROWIL IRES 2025 - Statistics Workshop",
    "section": "Tables",
    "text": "Tables\n\n\n\nSyntax\nDescription\n\n\n\n\nHeader\nTitle\n\n\nParagraph\nText"
  },
  {
    "objectID": "slides/template-seasons.html#callout-blocks-3",
    "href": "slides/template-seasons.html#callout-blocks-3",
    "title": "AI-PROWIL IRES 2025 - Statistics Workshop",
    "section": "Callout Blocks",
    "text": "Callout Blocks\n\n\n\n\n\n\nNote\n\n\nNote that there are five types of callouts, including: note, warning, important, tip, and caution.\n\n\n\n\n\n\n\n\n\nImportant\n\n\nDanger, callouts will really improve your writing.\n\n\n\n\n\n\n\n\n\nTip With Caption\n\n\nThis is an example of a callout with a caption."
  },
  {
    "objectID": "labs/lab-2_data-wrangling.html",
    "href": "labs/lab-2_data-wrangling.html",
    "title": "Lab 2: Data Wrangling Beginnings",
    "section": "",
    "text": "We have made it to Lab #2! We are going to keep practicing the skills we started using in the last week, except with using some new data. Before, we were using pre-installed data, but that won’t be the case IRL. When working with your own data, you will want to create a workflow of cleaning and wrangling your data in a reproducible way. These steps will likely occur for every new dataset that you work with.\nPlease complete the exercises below. Create a new .Rmd file and include the following at the top:\n---\ntitle: \"Lab 2: Data Wrangling Beginnings\"\nauthor: \"Your Name Here\"\ndate: \"`r Sys.Date()`\"\noutput: html_document\neditor_options: \n  chunk_output_type: console\n  markdown: \n    wrap: 72\n---\nYou should then be able to copy/paste everything below into your document.\nHere is a .Rmd file that you should be able to download and use as well.\n\nDownload Lab 2 (.Rmd)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the 🧶knitted .html file."
  },
  {
    "objectID": "labs/lab-2_data-wrangling.html#instructions",
    "href": "labs/lab-2_data-wrangling.html#instructions",
    "title": "Lab 2: Data Wrangling Beginnings",
    "section": "",
    "text": "We have made it to Lab #2! We are going to keep practicing the skills we started using in the last week, except with using some new data. Before, we were using pre-installed data, but that won’t be the case IRL. When working with your own data, you will want to create a workflow of cleaning and wrangling your data in a reproducible way. These steps will likely occur for every new dataset that you work with.\nPlease complete the exercises below. Create a new .Rmd file and include the following at the top:\n---\ntitle: \"Lab 2: Data Wrangling Beginnings\"\nauthor: \"Your Name Here\"\ndate: \"`r Sys.Date()`\"\noutput: html_document\neditor_options: \n  chunk_output_type: console\n  markdown: \n    wrap: 72\n---\nYou should then be able to copy/paste everything below into your document.\nHere is a .Rmd file that you should be able to download and use as well.\n\nDownload Lab 2 (.Rmd)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the 🧶knitted .html file."
  },
  {
    "objectID": "labs/lab-2_data-wrangling.html#scenario-and-goal",
    "href": "labs/lab-2_data-wrangling.html#scenario-and-goal",
    "title": "Lab 2: Data Wrangling Beginnings",
    "section": "Scenario and Goal",
    "text": "Scenario and Goal\nCongratulations, you’ve just collected data for a study on “Personality”! You administered a 10-item personality questionnaire, where participants responded on a 5-point Likert scale (1 = Strongly Disagree, 5 = Strongly Agree). This measure is called the “Ten Item Personality Inventory” (TIPI) and more information about the measure can be found here: TIPI Scale Info. Please refer to this page and documents to help with scoring the data and getting familiar with the measure.\nHowever, the raw data from the survey software is messy. Your goal in this lab is to import, clean, and score the data to prepare it for analysis. This process of turning raw data into usable data is called data wrangling, and it’s what researchers spend most of their time doing.\nYou will learn to: * Import a CSV file. * Rename variables for clarity. * Filter out participants based on data quality checks. * Reverse-score negatively worded items. * Compute a composite score for a psychological scale.\n\n\nGetting Data\nBe aware of your file structure and how things are organized. For some refreshers, take a look at the Resources and rstats.wtf\n\nDownload your data\nDownload Data from Drive (CSV)\nDownload Questionnaire From Drive (DOC)\n\n\n\nExercise 1: Importing and Inspecting the Data\nFirst, you need to load the appropriate packages and import your data. Use the tidyverse, rio, and here libraries.\n# Load the appropriate libraries.   \n\n# Write your import code here:   \n  ## This will look like:     \n  # your_data_name &lt;- import(here(\"path\", \"to\", \"file\", \"filename.csv))    \n\n\n# Use glimpse() to get a first look at the raw_data. \n# Write your code here:  \nQuestion 1: How many participants (rows) are in the raw, imported dataset?\n❓Your Answer: [Type your answer here]\n\n\n\nExercise 2: Renaming Variables for Clarity\nThe column names are a mixture of naming conventions. Let’s rename them to be consistent and convey the appropriate information.\nFirst, let’s take a look at what the names are. You can do this by using View(), but let’s use the names() function to list out all the column names.\nnames(Whatever_you_Named_your_data)\nThis will give you your list of names. You can see which ones we may want to rename. What does Q85 even mean? Thanks Qualtrics. Review the documentation for the survey to get a sense of what the questions are asking to properly rename the variables.\nFor now, let’s update the names as follows. It is helpful to keep everything lowercase to make it easier to type (but this is a personal preference), and make sure there aren’t any spaces in your variable names:\n\nID -&gt; id\nProgress -&gt; progress\nDuration (in seconds) -&gt; duration\nConsent -&gt; consent\nQ85 -&gt; sex_orient\nQ85_6_TEXT -&gt; sex_orient_txt\nSleep Quality -&gt; sleep_qual\nHours of Sleep -&gt; sleep_hours\n\n# Task: Use the rename() function to change the variable names as listed above.\n# Create a new object called `renamed_data`.\n# Hint: The syntax is: new_object &lt;- old_object %&gt;% rename(new_name_1 = old_name_1, new_name_2 = old_name_2)\n\n# Write your code here:\n# This part is a placeholder as the actual column names from the URL will differ.\n# Be sure to update the following template with the info from your own data\nrenamed_data &lt;- raw_data %&gt;%\n  rename(participant_id = country, \n         grit_1 = year,\n         grit_2 = population)\n         # ... and so on for the other variables\n\n# Print the first few rows of your new `renamed_data` object to check your work.\nhead(renamed_data)\n\n\n\nExercise 3: Filtering for Data Quality\nOur survey includes variables that allow us to see how long they took and what percentage they completed. We should remove participants who did not finish the survey, as well as those who finished it too quickly.\nThis will be done using the filter() function (more about filter). Use filter to keep participants where their progress is equal to 100. You will also want to remove participants who completed the survey in less than 7 minutes (note: the Duration variable is in seconds).\n# Create a new object called `filtered_data`.\n\n# Example code:\n# filtered_data &lt;- renamed_data %&gt;%\n#   filter(Progress == 100) %&gt;% \n#   filter(Duration ==, &lt;, &gt; 1000)\nQuestion 2: How many participants remain from your original dataset? How many participants did you remove with your filters?\n❓Your Answer: [Type your answer here]\n\n\n\nExercise 4: Reverse-Scoring Items\nIn a lot of psychological research, we need to reverse score variables. They are often worded in a negative/positive way compared to the rest of the items. Review the TIPI documentation to see what items need to be reverse scored.\nFor example, Item 2 is a item that should reflect “Agreeableness”, but the rated words are “Critical, quarrelsome”. Therefore low score on this item would reflect high amounts of Agreeableness.\nThe formula for reverse scoring an item is: (Maximum Possible Value + 1) - Original Score. So, for the TIPI, it’s 8 - TIPI_2.\nTo create/compute a new variable we use the mutate() function (more about mutate). I like to remember this function name because we are “mutating” the data and introducing another “growth” or something extra that wasn’t there before.\n# Task: Use the mutate() function to create new, reverse-scored variables.\n# Use a new name to indicate which items are reverse-scored.\n# Create a new object called `scored_data`.\n# Hint: The syntax is: \n  # new_object &lt;- old_object %&gt;% \n  #   mutate(new_variable = computation, \n  #          new_variable2 = computation)\n\n\n# Exmple code:\n# scored_data &lt;- filtered_data %&gt;%\n#   mutate(TIPI_2r = 8 - TIPI_2)\n\n\n\n# Print the first few rows, showing only the original and new reverse-scored item to check your work.\n\n# scored_data %&gt;% select(TIPI_2, TIPI_2r) %&gt;% head()\nQuestion 3: If a participant’s original score on TIPI_4 was a 6, what would their score be on the new TIPI_4r variable?\n❓Your Answer: [Type your answer here]\n\n\n\nExercise 5: Computing and Finalizing the Scored File\nNow we are ready to compute the final score! There are individual subscales for each of the 5 factors of the Big 5 Personality Inex. Compute the 5 scales. Remember to use the reverse-scored items (TIPI_2r), not the original one.s\n# Task 1: Use mutate() to calculate the total grit score.\n# Sum the items corresponding to each scale.\n# Call the new variables 'extra', 'agree', 'consc', 'emo', 'open.\n# Overwrite your `scored_data` object with this new version.\n\n# Task 2: Create a final, clean dataset.\n# Use select() to keep only the 'id' and Big 5 scale columns.\n# Call this object `final_data`.\n# Conceptual code:\n# final_data &lt;- scored_data %&gt;%\n#   select(id, agree, ...)\n\n\n\n# Task 3: Calculate the mean and standard deviation of each of the subscale scores.\nQuestion 4: What would be the highest possible Emotional Stability score a participant could get? What would be the lowest?\n❓Your Answer: [Type your answer here]\nQuestion 5: Report the mean’s and standard deviations of each of the subscale scores\n❓Your Answer:\n\nExtraversion:\nAgreeableness:\nConscientiousness:\nEmotional Stability:\nOpenness to Experience:\n\n\n\n\nExercise 6: Visualize Relationships\nWe often want to see the relationship between 2 variables. This is often done using a scatterplot. Select 2 scales that you would like to see the relationship between. Use the code from the previous lab/class to create a scatterplot of the relationship. Take a look at this cheat sheet to help with ggplot2!\n# Using ggplot and the scored data you have, generate a scatterplot. It can be as simple or as fancy as you would like (try putting a title and changing the axis names)\n\n\n\n# Use the cheat sheet and other materials to put a straight line to the data (Hint: add another layer with a smooth geom)\nQuestion 6.1: Visually inspect the chart you have and describe the relationship below. Be sure to include the two variables and an estimate of your correlation in your answer.\n❓Your Answer:\n# Compute a correltion for your variables\n# Hint: use the `cor.test()` function. You will need to specify the variable names as `name_of_data$name_of_variable`\n  \n  # Example\n    # cor.test(starwars$height, starwars$mass)\nQuestion 6.2: Calculate the correlation coefficient for your two variables of interest (refer here for more info). Report the correlation, and reflect on how close or how far away your initial estimate was. Do your best here. I recognize that we haven’t really gone over this just yet.\n❓Your Answer:\n\nEnd of Lab. Don’t forget to Knit! 🧶"
  },
  {
    "objectID": "materials.html",
    "href": "materials.html",
    "title": "Materials",
    "section": "",
    "text": "TIPI_Data TIPI Data (.csv)\nTIPI Documentation - TIPI Documentation (.docx)\nVisualization Dataset Download Viz Activity Data (.csv)\nBechdel Dataset  Download Bechdel Data (.csv)",
    "crumbs": [
      "Materials"
    ]
  },
  {
    "objectID": "materials.html#data-for-activities",
    "href": "materials.html#data-for-activities",
    "title": "Materials",
    "section": "",
    "text": "TIPI_Data TIPI Data (.csv)\nTIPI Documentation - TIPI Documentation (.docx)\nVisualization Dataset Download Viz Activity Data (.csv)\nBechdel Dataset  Download Bechdel Data (.csv)",
    "crumbs": [
      "Materials"
    ]
  },
  {
    "objectID": "materials.html#markdowns-for-activities",
    "href": "materials.html#markdowns-for-activities",
    "title": "Materials",
    "section": "Markdowns For Activities",
    "text": "Markdowns For Activities\nData Wrangling Origins Activity Wrangling Origins (.Rmd)\nDescribe & Visualize Describe & Visualize (.Rmd)\nDark R’s - Dark Rs (.Rmd)",
    "crumbs": [
      "Materials"
    ]
  },
  {
    "objectID": "topics/sem.html",
    "href": "topics/sem.html",
    "title": "Structural Equation Modeling",
    "section": "",
    "text": "SEM\nThere are so many different directions that we can go in when it comes to Structural Equation Modeling. In my opinion, it is one of the most versatile techniques that can be used for the type of work that I do. One major strength of SEM is that it aligns with the way that we conceptualize various psychological constructs.\nFor example, take a second and ask yourself “What is depression or anxiety?”. I’ll wait.\nYou better not be reading this if you didn’t think about the question before. Is depression/anxiety something that can be directly measured and observed in the same way that mass or distance can? Can we take someone’s blood or do a scan and point to the output and say “there is the depression”?\nWe can’t.\nThen we are working in the space that is unable to be directly observed. We have to take multiple measures of things that we think are related to the construct. Once we have those measurements, we can look at them together and assume that because we are seeing these things, then someone is experienced depression or anxiety.\nTo accurately model this, we can implement Structural Equation Modeling. This deals with “latent” (or unobserved) variables. By taking manifest (observed) variables, we can investigate the overall variance and covariance among these items to determine an underlying, latent construct.\nA good example of a latent variable is IQ and the overall “g-factor”. We use these individual tests that we can observe to make claims about overall intelligence which is not something we are able to directly tap into.\n\n\n\nSEM in R\nThere have been lots of advancements in computing and using R for SEM have become increasingly popular (another program to use is M-Plus, but you have to pay for that, so we won’t talk about it). The package that I like to use for SEM in R is lavaan.\n\nlibrary(lavaan)\n\nThis is lavaan 0.6-19\nlavaan is FREE software! Please report any bugs.\n\n\nThere is a whole lot of things that we can do, and I will leave it up to the group to determine where we want to go. I’ve given a workshop on Random Intercept Cross-Lagged Panel models if we want to do that. The slides and script can be found over in Materials. Otherwise, here are some areas we can explore:\n\nExploratory Factor Analysis\nConfirmatory Factor Analysis\nPath Analysis\nLatent Growth Curve Models\nRandom Intercept Cross Lagged Panel Model",
    "crumbs": [
      "Topics",
      "Structural Equation Modeling"
    ]
  },
  {
    "objectID": "topics/topic-1.html",
    "href": "topics/topic-1.html",
    "title": "Getting Started",
    "section": "",
    "text": "Welcome to the workshop (I hope this isn’t the first time I am welcoming you)! I am very excited to get to work with you throughout this workshop. We will begin with a brief exploration into using R & R-Studio, and an overall emphasis on reproducible workflows. This first portion will set up\nWe’ll then dive right into our primary tool, R. This session will go over installing R and RStudio, navigating the interface, understanding R projects, and learning the foundational syntax of the R language and the tidyverse, including data types and basic functions.\n\n\n\nLaptop\nInstall R and R-Studio (https://posit.co/download/rstudio-desktop/)\n\n\n\n\n💻Getting Started\n\n\n\n📋Getting Comfy with R\n📋More Comfy with R",
    "crumbs": [
      "Topics",
      "Getting Started"
    ]
  },
  {
    "objectID": "topics/topic-1.html#prepare",
    "href": "topics/topic-1.html#prepare",
    "title": "Getting Started",
    "section": "",
    "text": "Laptop\nInstall R and R-Studio (https://posit.co/download/rstudio-desktop/)",
    "crumbs": [
      "Topics",
      "Getting Started"
    ]
  },
  {
    "objectID": "topics/topic-1.html#slides",
    "href": "topics/topic-1.html#slides",
    "title": "Getting Started",
    "section": "",
    "text": "💻Getting Started",
    "crumbs": [
      "Topics",
      "Getting Started"
    ]
  },
  {
    "objectID": "topics/topic-1.html#activities",
    "href": "topics/topic-1.html#activities",
    "title": "Getting Started",
    "section": "",
    "text": "📋Getting Comfy with R\n📋More Comfy with R",
    "crumbs": [
      "Topics",
      "Getting Started"
    ]
  },
  {
    "objectID": "weeks/week-3.html",
    "href": "weeks/week-3.html",
    "title": "Week 3 - Describe, Visualize, Communicize",
    "section": "",
    "text": "We are now in the third week and you are all probably thinking about how much you dislike R and do not ever want to look at the here() library again. But we are going to have to do just that. Importing and getting started are one of the hardest things to do when first working with R. And then trying to make things reproducible is another thing. We are going to practice this A LOT. Especially right in the beginning.\nThis week we are going to expand on some data wrangling to get more comfortable with dplyr and the larger tidyverse. Here is a good website that can also be helpful. Then we will move into an overview of descriptive statistics and how to get them using R. Finally, we will continue with visualizations using ggplot2. With time, we will start introducing how to talk communicate these types of statistics in a manuscript.\n\n\n📖Read Chapter 5 - LSR\n📖Read Chapter 1 & 3 - R4DS\n\n\n\n💻 Data Wrangling\n💻 Describe & Visualize\n\n\n\nDescribing & Visualizing\n\n\n\n📋Lab 3 - Describe and Visualize\n📖Read Chapter 2 - IMS\n📖Read Chapter 3 - MSR\n📖Read Chapter 7 - ST\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-3.html#prepare",
    "href": "weeks/week-3.html#prepare",
    "title": "Week 3 - Describe, Visualize, Communicize",
    "section": "",
    "text": "📖Read Chapter 5 - LSR\n📖Read Chapter 1 & 3 - R4DS"
  },
  {
    "objectID": "weeks/week-3.html#slides",
    "href": "weeks/week-3.html#slides",
    "title": "Week 3 - Describe, Visualize, Communicize",
    "section": "",
    "text": "💻 Data Wrangling\n💻 Describe & Visualize"
  },
  {
    "objectID": "weeks/week-3.html#in-class-activity",
    "href": "weeks/week-3.html#in-class-activity",
    "title": "Week 3 - Describe, Visualize, Communicize",
    "section": "",
    "text": "Describing & Visualizing"
  },
  {
    "objectID": "weeks/week-3.html#for-next-time",
    "href": "weeks/week-3.html#for-next-time",
    "title": "Week 3 - Describe, Visualize, Communicize",
    "section": "",
    "text": "📋Lab 3 - Describe and Visualize\n📖Read Chapter 2 - IMS\n📖Read Chapter 3 - MSR\n📖Read Chapter 7 - ST\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-1.html",
    "href": "weeks/week-1.html",
    "title": "Week 1",
    "section": "",
    "text": "Welcome to the course! I am very excited to get to work with you this semester on our journey into statistics. During our first class, we will review the syllabus and the plan for the course, followed by walking through the structure of each of the classes.\nWe’ll then dive right into our primary tool, R. This session will go over installing R and RStudio, navigating the interface, understanding R projects, and learning the foundational syntax of the R language and the tidyverse, including data types and basic functions.\n\n\n\nInstall R and R-Studio (https://posit.co/download/rstudio-desktop/)\nBring Laptop\n\n\n\n\n💻 Getting Started - Syllabus\n💻Getting Started - Data\n\n\n\nGetting Comfy with R\n\n\n\n📋Lab 1 - Foundations of a Data Workflow\n📖Read Chapter 1 & 2 - ST\n📖Read Chapter 2 - MSR\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-1.html#prepare",
    "href": "weeks/week-1.html#prepare",
    "title": "Week 1",
    "section": "",
    "text": "Install R and R-Studio (https://posit.co/download/rstudio-desktop/)\nBring Laptop"
  },
  {
    "objectID": "weeks/week-1.html#slides",
    "href": "weeks/week-1.html#slides",
    "title": "Week 1",
    "section": "",
    "text": "💻 Getting Started - Syllabus\n💻Getting Started - Data"
  },
  {
    "objectID": "weeks/week-1.html#in-class-activity",
    "href": "weeks/week-1.html#in-class-activity",
    "title": "Week 1",
    "section": "",
    "text": "Getting Comfy with R"
  },
  {
    "objectID": "weeks/week-1.html#for-next-time",
    "href": "weeks/week-1.html#for-next-time",
    "title": "Week 1",
    "section": "",
    "text": "📋Lab 1 - Foundations of a Data Workflow\n📖Read Chapter 1 & 2 - ST\n📖Read Chapter 2 - MSR\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "activities/describe-viz2.html",
    "href": "activities/describe-viz2.html",
    "title": "Describing and Visualizing Data",
    "section": "",
    "text": "We are going to continue to practice importing data and making a reproducible workflow. In this activity, you will be expanding the types of plots you are able to use.\nWe will be using data from the Bechdel test, a measure of the representation of women in fiction. You will be asked to do some Exploratory Data Analysis.\nHere are the things that you will need for this lab:\nDescribe & Visualize Markdown - Describe & Visualize (.Rmd)\nBechdel Dataset  Download Bechdel Data (.csv)"
  },
  {
    "objectID": "activities/describe-viz2.html#instructions",
    "href": "activities/describe-viz2.html#instructions",
    "title": "Describing and Visualizing Data",
    "section": "",
    "text": "We are going to continue to practice importing data and making a reproducible workflow. In this activity, you will be expanding the types of plots you are able to use.\nWe will be using data from the Bechdel test, a measure of the representation of women in fiction. You will be asked to do some Exploratory Data Analysis.\nHere are the things that you will need for this lab:\nDescribe & Visualize Markdown - Describe & Visualize (.Rmd)\nBechdel Dataset  Download Bechdel Data (.csv)"
  },
  {
    "objectID": "activities/describe-viz2.html#scenario-and-goal",
    "href": "activities/describe-viz2.html#scenario-and-goal",
    "title": "Describing and Visualizing Data",
    "section": "Scenario and Goal",
    "text": "Scenario and Goal\nIn this activity, you will act as a data journalist exploring a dataset on movies. We will use the data from the FiveThirtyEight story “The Dollar-And-Cents Case Against Hollywood’s Exclusion of Women.”\nThis analysis is about the Bechdel test, a measure of the representation of women in fiction.\nYour goal is to import, describe, and visualize this data to understand the characteristics of movies in the dataset and see if there are relationships between a movie’s budget, its box office gross, and its Bechdel Test rating. This is the critical first step in any analysis, known as Exploratory Data Analysis (EDA)."
  },
  {
    "objectID": "activities/describe-viz2.html#variables-of-interest",
    "href": "activities/describe-viz2.html#variables-of-interest",
    "title": "Describing and Visualizing Data",
    "section": "Variables of Interest",
    "text": "Variables of Interest\n\nyear: The year of movie release\nclean_test: Bechdel test result:\n\nok = passes test\ndubious\nmen = women only talk about men\nnotalk = women don’t talk to each other\nnowomen = fewer than two women\n\nbinary: Bechdel Test PASS vs FAIL binary\nbudget_2013: Total movie budget"
  },
  {
    "objectID": "activities/describe-viz2.html#exercises",
    "href": "activities/describe-viz2.html#exercises",
    "title": "Describing and Visualizing Data",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1: Importing and Inspecting\nFirst, you need to set up your RMarkdown to get it ready for importing the data and using the appropriate libraries. Be sure to have all libraries listed here in the first code chunk along with importing the data. I should not see any lines that say install.packages().\nI will attempt to reproduce your output in my own computer, so be sure that your code is reproducible.\nQuestion 1: Look at the output from your overview. How many total movies are in this database? And what year is the latest movie?\nYour Answer:\nQuestion 2: Calculate the Average budget of the whole dataset. Then, calculate the average for only movies in the year 2000.\nYour Answer:\n\n\n\nExercise 2: Grouped Descriptive Statistics\nAverages for the whole dataset are useful, but we are often more interested in comparing averages between groups. Let’s see if the average budget differs for movies that pass the Bechdel Test versus those that fail. The binary variable tells us this (“PASS” or “FAIL”).\nQuestion 3: Based on your summary table, do movies that pass or fail the Bechdel test have a higher average (mean) budget?\nYour Answer:\n\n\n\nExercise 3: Visualizing a Distribution (Histogram)\nLet’s visualize the distribution of domestic gross earnings (adjusted for 2013) across all the movies.\nQuestion 4: Describe the shape of the distribution you see in the histogram. Is it symmetric (like a bell curve), or is it skewed in one direction? Where do most movies’ earnings seem to be clustered?\nYour Answer:\n\n\n\nExercise 4: Examining the Bechdel Test distribution\nNow we want to see how many movies fall into each of the Bechdel categories. Generate a barplot of the clean_test variable to see what the distribution of the test is.\nThen choose a year in the dataset, create a similar plot (but only for that year). Therefore you should have 2 plots below:\nQuestion 5: Examine both charts and describe the similarities and differences that you are noticing.\nAnswer:\n\n\n\nExercise 5: Comparing Groups with a Boxplot\nNow let’s visually compare the inflation-adjusted international gross (intgross_2013) for movies that pass the Bechdel test versus those that fail. A boxplot is an excellent way to see differences in the median and spread between groups.\nQuestion 6: Look at the boxplot. The thick horizontal line in the middle of each box represents the median. Does there appear to be a large difference in the median domestic gross between movies that pass and fail the test?\nYour Answer:\n\nEnd. You’ve now practiced exploratory data analysis! It is always important to visualize your data to get a good sense of what you are working with. Don’t forget to try to Knit! 🧶"
  },
  {
    "objectID": "activities/describe-viz1.html",
    "href": "activities/describe-viz1.html",
    "title": "Describing & Visualizing",
    "section": "",
    "text": "Goal: Work on importing data as well as being able to build a pipeline from descriptives to reporting to visualizing."
  },
  {
    "objectID": "activities/describe-viz1.html#create-a-new-markdown-document",
    "href": "activities/describe-viz1.html#create-a-new-markdown-document",
    "title": "Describing & Visualizing",
    "section": "Create a new Markdown Document",
    "text": "Create a new Markdown Document\n\nGo to File &gt; New File &gt; R Markdown\nProvide the title “Describe & Visualize” and input your name as the author\nA script will open in the Source pane. Remove unnecessary code."
  },
  {
    "objectID": "activities/describe-viz1.html#setting-it-up",
    "href": "activities/describe-viz1.html#setting-it-up",
    "title": "Describing & Visualizing",
    "section": "Setting it up",
    "text": "Setting it up\n\nCreate a Code Chunk\nLoad the tidyverse, psych and sjPlot libraries (Install them if you need to)"
  },
  {
    "objectID": "activities/describe-viz1.html#the-data",
    "href": "activities/describe-viz1.html#the-data",
    "title": "Describing & Visualizing",
    "section": "The Data",
    "text": "The Data\nDownload Viz Activity Data (.csv)\nDownload the data and move it to the correct folder so that you can access it in this activity.\nYour dataset is from a larger study that was examining the overall impact of sleep on energy (and vice versa). Students in different areas across the country completed various questionnaires. The current data is a selection of overall sleep quality rating (0-100) and overall energy level (0-100) across all cities. You will be asked to examine these variables in a descriptive and visual way for your specific city.\nBreak up into your groups and work to visualize your assigned cities dataset.\n\n\n\nAlbuquerque\nChicago\nPittsburgh\n\n\nAtlanta\nDenver\nRochester\n\n\nBoston\nIthaca\nSacramento\n\n\nChampaign-Urbana\nMadison\nSeattle\n\n\n\nImport the data into your R file. I would suggest putting this line within the code chunk that you have your libraries in.\nFocus on having reproducible code! You may need to share your file with someone else. They should be able to run it."
  },
  {
    "objectID": "activities/describe-viz1.html#questions",
    "href": "activities/describe-viz1.html#questions",
    "title": "Describing & Visualizing",
    "section": "Questions",
    "text": "Questions\nWith the data that you have imported, follow the following steps and answer the questions along the way.\n\nNumber of Observations\n❓After importing, how many total observations are there?\n✅Answer:\n\nThe dataset has all cities involved in the study. You only want to keep the data from your city. Create a new dataset that has only your city in it.\n\n\n\n\n\n\nTip\n\n\n\nWe’ve used dplyr a lot to move our data around. Maybe it has something to do with select() or filter() or mutate()\n\n\n❓How many total observations are there in your new dataset (for your city)?\n✅Answer:\n\n\n\nCalculating Descriptives\nYou should now have 2 datasets (1 for the entire sample, and 1 for your city). Calculate and report the mean and standard deviation for your city. Then calcullate and report the mean and standard deviation for the whole sample.\n\n\n\nYour City\nTotal Sample\n\n\n\n\nSleep Mean:\nSleep Mean:\n\n\nSleep SD:\nSleep SD:\n\n\nEnergy Mean:\nEnergy Mean:\n\n\nEnergy SD:\nEnergy SD:\n\n\n\n❓How are the mean and standard deviations similar/different?\n✅Answer:\n\n\n\nReporting Descriptive Statistics\nNow that you have each of the pieces of information calculated for the entire sample and your specific city, you can report it in text. It is important to be able to report these basic descriptive statistics in a meaningful way, so we will practice it as often as possible. Here is an example:\n\nThe sample as a whole was relatively young (M = 19.22, SD = 3.45).\nThe average amount of drinks consumed was 3.37 (SD = 0.92).\n\n❓Report the means and standard deviations in text for the two variables in your city sample.\n✅Answer:\n\n\n\nVisualizing\nWe have two variables and we would like to examine the relationship between them. Use a scatterplot to highlight the relationship between these two variables for your city.\nBe sure that your plot has a clear main title and clear labels for each axis.\n\n\n\n\n\n\nTip\n\n\n\nLook back to the lecture or past labs and pull in some of the ggplot code that you have! You can always re-use code.\n\n\n❓Describe the overall look of the data for your city.\n✅Answer:\n\nAs a class, we will review the different cities to see if we would be able to come to some broad conclusion.\nEnd of the document. Remember to Knit and upload the html and .Rmd to myCourses."
  },
  {
    "objectID": "activities/basic_intro2.html",
    "href": "activities/basic_intro2.html",
    "title": "Foundations of a Data Workflow",
    "section": "",
    "text": "Welcome to your first lab! The goal of this assignment is to move beyond basic syntax and begin practicing a reproducible data analysis workflow.\nPlease complete the exercises below. Create a new .Rmd file and include the following in the yaml header:\n---\ntitle: \"Foundations of a Data Workflow\"\nauthor: \"Your Name Here\"\ndate: \"`r Sys.Date()`\"\noutput: html_document\neditor_options: \n  chunk_output_type: console\n  markdown: \n    wrap: 72\n---\nYou should then be able to copy/paste everything below into your document.\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the final .html file.\n\n\n\nA major strength of R is its ecosystem of packages that add new functionality. We will use the tidyverse package in almost every analysis we do. The ggplot2 package, which is part of the tidyverse, contains a dataset called msleep about mammal sleep patterns.\n# Task 1: Load the tidyverse package.\n# Write your code here:\n\n\n# Task 2: The `msleep` dataset is available after loading the tidyverse.\n# Use the `glimpse()` function to get a quick overview of the `msleep` dataset.\n# Write your code here:\n\n\n# Task 3: Now use the `summary()` function on the `msleep` dataset.\n# Write your code here:\n❓Question 1: Based on the output of glimpse(), how many rows (observations) and columns (variables) are in the msleep dataset?\nYour Answer: [Type your answer here]\n❓Question 2: What is one key difference between the information provided by glimpse() and the information provided by summary() for a variable like sleep_total?\nYour Answer: [Type your answer here]\n\n\n\n\nLet’s say we are only interested in herbivores. We can use functions from the dplyr package (part of the tidyverse) to create a new, sorted dataset.\n# Task 1: Create a new object called `herbivores` that contains only the animals\n# from the `msleep` dataset where the `vore` column is equal to \"herbi\".\n# Hint: The syntax for filtering is: new_object &lt;- old_object %&gt;% filter(column_name == \"value\")\n# Write your code here:\n\n\n# Task 2: Now, sort this new `herbivores` dataset by total sleep time, from highest to lowest.\n# You can overwrite the `herbivores` object with the newly sorted version.\n# Hint: Use the `arrange()` function with `desc()` for descending order.\n# The syntax is: object &lt;- object %&gt;% arrange(desc(column_to_sort_by))\n# Write your code here:\n\n\n# Now, print the new, sorted `herbivores` object to see the result.\n❓Question: After sorting, which herbivore sleeps the most? How many hours does it sleep?\nYour Answer: [Type your answer here]\n\n\n\n\nData visualization is a critical part of understanding data. Let’s create a scatterplot to see if there is a relationship between how long a herbivore sleeps and how much time it spends dreaming.\n# Task: Create a scatterplot using ggplot().\n# We want to plot the `sleep_rem` (dreaming sleep) on the y-axis and `sleep_total` on the x-axis,\n# using only our `herbivores` dataset.\n# Fill in the blanks in the code below.\n\nggplot(data = ________, aes(x = _______, y = _________)) +\n  geom_????? +\n  labs(title = \"Total Sleep vs. REM Sleep in Herbivores\",\n       x = \"Total Sleep (hours)\",\n       y = \"REM Sleep (hours)\")\n❓Question 1: Look at the plot you created. In one or two sentences, describe the relationship you see between total sleep and REM sleep for these animals. Is the relationship positive, negative, or is there no clear relationship?\nYour Answer: [Type your answer here]\n❓Question 2: Are there any animals that seem unusual or stand out from the general pattern? Briefly describe one.\nYour Answer: [Type your answer here]\n\n\n\n\nOften, we want to calculate a single value to summarize our data. The summarise() function is perfect for this.\n# Task: Calculate the average (mean) total sleep time for ALL mammals in the original `msleep` dataset.\n# Hint: The syntax is: dataset %&gt;% summarise(new_variable_name = mean(column_name, na.rm = TRUE))\n# The `na.rm = TRUE` part is important because it tells R to ignore any missing values.\n# Write your code here:\n❓Question: What is the mean total sleep time for all mammals in the dataset?\nYour Answer: [Type your answer here]\n\nEnd. Don’t forget to Knit! 🧶"
  },
  {
    "objectID": "activities/basic_intro2.html#instructions",
    "href": "activities/basic_intro2.html#instructions",
    "title": "Foundations of a Data Workflow",
    "section": "",
    "text": "Welcome to your first lab! The goal of this assignment is to move beyond basic syntax and begin practicing a reproducible data analysis workflow.\nPlease complete the exercises below. Create a new .Rmd file and include the following in the yaml header:\n---\ntitle: \"Foundations of a Data Workflow\"\nauthor: \"Your Name Here\"\ndate: \"`r Sys.Date()`\"\noutput: html_document\neditor_options: \n  chunk_output_type: console\n  markdown: \n    wrap: 72\n---\nYou should then be able to copy/paste everything below into your document.\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the final .html file.\n\n\n\nA major strength of R is its ecosystem of packages that add new functionality. We will use the tidyverse package in almost every analysis we do. The ggplot2 package, which is part of the tidyverse, contains a dataset called msleep about mammal sleep patterns.\n# Task 1: Load the tidyverse package.\n# Write your code here:\n\n\n# Task 2: The `msleep` dataset is available after loading the tidyverse.\n# Use the `glimpse()` function to get a quick overview of the `msleep` dataset.\n# Write your code here:\n\n\n# Task 3: Now use the `summary()` function on the `msleep` dataset.\n# Write your code here:\n❓Question 1: Based on the output of glimpse(), how many rows (observations) and columns (variables) are in the msleep dataset?\nYour Answer: [Type your answer here]\n❓Question 2: What is one key difference between the information provided by glimpse() and the information provided by summary() for a variable like sleep_total?\nYour Answer: [Type your answer here]\n\n\n\n\nLet’s say we are only interested in herbivores. We can use functions from the dplyr package (part of the tidyverse) to create a new, sorted dataset.\n# Task 1: Create a new object called `herbivores` that contains only the animals\n# from the `msleep` dataset where the `vore` column is equal to \"herbi\".\n# Hint: The syntax for filtering is: new_object &lt;- old_object %&gt;% filter(column_name == \"value\")\n# Write your code here:\n\n\n# Task 2: Now, sort this new `herbivores` dataset by total sleep time, from highest to lowest.\n# You can overwrite the `herbivores` object with the newly sorted version.\n# Hint: Use the `arrange()` function with `desc()` for descending order.\n# The syntax is: object &lt;- object %&gt;% arrange(desc(column_to_sort_by))\n# Write your code here:\n\n\n# Now, print the new, sorted `herbivores` object to see the result.\n❓Question: After sorting, which herbivore sleeps the most? How many hours does it sleep?\nYour Answer: [Type your answer here]\n\n\n\n\nData visualization is a critical part of understanding data. Let’s create a scatterplot to see if there is a relationship between how long a herbivore sleeps and how much time it spends dreaming.\n# Task: Create a scatterplot using ggplot().\n# We want to plot the `sleep_rem` (dreaming sleep) on the y-axis and `sleep_total` on the x-axis,\n# using only our `herbivores` dataset.\n# Fill in the blanks in the code below.\n\nggplot(data = ________, aes(x = _______, y = _________)) +\n  geom_????? +\n  labs(title = \"Total Sleep vs. REM Sleep in Herbivores\",\n       x = \"Total Sleep (hours)\",\n       y = \"REM Sleep (hours)\")\n❓Question 1: Look at the plot you created. In one or two sentences, describe the relationship you see between total sleep and REM sleep for these animals. Is the relationship positive, negative, or is there no clear relationship?\nYour Answer: [Type your answer here]\n❓Question 2: Are there any animals that seem unusual or stand out from the general pattern? Briefly describe one.\nYour Answer: [Type your answer here]\n\n\n\n\nOften, we want to calculate a single value to summarize our data. The summarise() function is perfect for this.\n# Task: Calculate the average (mean) total sleep time for ALL mammals in the original `msleep` dataset.\n# Hint: The syntax is: dataset %&gt;% summarise(new_variable_name = mean(column_name, na.rm = TRUE))\n# The `na.rm = TRUE` part is important because it tells R to ignore any missing values.\n# Write your code here:\n❓Question: What is the mean total sleep time for all mammals in the dataset?\nYour Answer: [Type your answer here]\n\nEnd. Don’t forget to Knit! 🧶"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "rempsych - Convenience functions for psychology\ntidySEM - Provides a ‘tidy’ workflow for conducting, reporting and plotting Structural Equation Modeling\neasystats - An R Framework for Easy Statistical Modeling, Visualization, and Reporting",
    "crumbs": [
      "Additional Stuff"
    ]
  },
  {
    "objectID": "resources.html#installing-r-r-studio",
    "href": "resources.html#installing-r-r-studio",
    "title": "Resources",
    "section": "Installing R & R-Studio",
    "text": "Installing R & R-Studio\nTo get started with using the statistical software, we first must install it! Here is a guide that was put together to help with the installation process. Throughout this guide, you will install R followed by R-Studio (a program to make R more user friendly). \nWe will go over this during the first day of class, so this guide is just to use as reference. \nThings needed:\n\nComputer\nInternet Connection\nA coffee or preferred beverage usually helps!\n\n\nR: Download and Install\nInformation taken from “Hands-On Programming with R”\nR is maintained by an international team of developers who make the language available through the web page ofThe Comprehensive R Archive Network. The top of the web page provides three links for downloading R. Follow the link that describes your operating system: Windows or Mac.\n\nWindows\nTo install R on Windows, click the “Download R for Windows” link.Then click the “base” link. Next, click the first link at the top of the new page. This link should say something like “Download R 4.3.1 for Windows,” except the 4.3.1 will be replaced by the most current version of R. The link downloads an installer program, which installs the most up-to-date version of R for Windows. Run this program and step through the installation wizard that appears. The wizard will install R into your program files folders and place a shortcut in your Start menu. Note that you’ll need to have all of the appropriate administration privileges to install new software on your machine.\n\n\nMac\nTo install R on a Mac, click the “Download R for Mac’’ link. Next, click on the “R-4.3.1-arm64.pkg” package link (or the package link for the most current release of R that is appropriate for your computer). An installer will download to guide you through the installation process, which is very easy. The installer lets you customize your installation, but the defaults will be suitable for most users. I’ve never found a reason to change them. If your computer requires a password before installing new programs, you’ll need it here.\n\n\n\nUsing R\nR isn’t a program that you can open and start using, like Microsoft Word or Internet Explorer. Instead, R is a computer language, like C, C++, or UNIX. You use R by writing commands in the R language and asking your computer to interpret them. In the old days, people ran R code in a UNIX terminal window—as if they were hackers in a movie from the 1980s. Now almost everyone uses R with an application called RStudio, and I recommend that you do, too.\nGo ahead and try to open R without using R-Studio. You will get something like this:",
    "crumbs": [
      "Additional Stuff"
    ]
  },
  {
    "objectID": "resources.html#r-studio-download-and-install",
    "href": "resources.html#r-studio-download-and-install",
    "title": "Resources",
    "section": "R-Studio: Download and Install",
    "text": "R-Studio: Download and Install\nRStudio is an application like Microsoft Word—except that instead of helping you write in English, RStudio helps you write in R. We will use RStudio throughout because it makes working with R SO much easier. Plus there are a lot of additional functionalities that RStudio has that will expand what you can do (e.g., RMarkdown). Also, the RStudio interface looks the same for the various operating systems which will make teaching and your experience with the material a lot easier.\nRStudio (the company) has recently changed their name to Posit. To download RStudio, you can navigate to the Posit download page for “RStudio Desktop”. We have already completed Step 1 (you could have just come here to download it, but it is helpful to know where to get the latest versions and materials)! All you have to do is select the box under “2: Install RStudio” to download. It should recognize the operating system that you are using, but if it does not, you will just need to scroll down the page to identify the appropriate installer.\nNow you are all set and ready to go! Nice job following the instructions and getting R and RStudio on your computer. Next you can begin to customize and get used to using RStudio. Remember, this is not something that is scary or a thing you can “break”. When in doubt, check out Google or reach out to the professor!",
    "crumbs": [
      "Additional Stuff"
    ]
  },
  {
    "objectID": "resources.html#setting-things-up",
    "href": "resources.html#setting-things-up",
    "title": "Resources",
    "section": "Setting things up",
    "text": "Setting things up\nHere are some things that I am going to suggest to make your experience with R as good as we possibly can. Some of the suggestions here are related to your workflow while others are direct settings within R…and some are both. We are all complex creatures. \nA lot of my suggestions will come from “What They Forgot to Teach You About R”. As I use other sites or things, I will do my best to have links to the original.\nThis list will continue to develop and expand. It is a work in progress (just like most of us)\n\nStart R with a blank slate each time Link\nNavigate to Tools &gt; Global Options\nBy default, R Studio saves all of the objects in your environment. In general, this is not ideal, because it means that you may have taken steps interactively that are not documented in your code.\n\n\n\n\n\nThis would be like when you are baking, and you follow the recipe, but then you add in some cinnamon and nutmeg which the recipe doesn’t call for. You also measure out some extra chocolate chips and brown sugar, but you end up not using that. The cookies come out fantastic and you want to make them again. You open up your kitchen and the cinnamon, nutmeg, chocolate chips and brown sugar are all there, but nothing says that you need them in your recipe. We don’t want to keep all the old information. We only want what is in the recipe (after we update it to include the extra spices).\n\n\nDecorate\nNavigate to Tools &gt; Global Options &gt; Appearance\nThis is all yours! Take ownership and find a cool theme that you like. Make it look nice and how you want it.\n\n\n\n\n\nRight now I am rocking the “Chaos” theme with my fonts a little larger because apparently I am getting older.",
    "crumbs": [
      "Additional Stuff"
    ]
  },
  {
    "objectID": "resources.html#goal",
    "href": "resources.html#goal",
    "title": "Resources",
    "section": "Goal",
    "text": "Goal\nThe focus of this section is to introduce you to some simple tools that will allow you to calculate, visualize and manipulate the data in R. We will use some of the skills we worked through during our class on introducing R, such as creating objects, working with and loading in data, installing packages as well as learning how to use some new functions.",
    "crumbs": [
      "Additional Stuff"
    ]
  },
  {
    "objectID": "resources.html#recap-directory---wheres-my-file",
    "href": "resources.html#recap-directory---wheres-my-file",
    "title": "Resources",
    "section": "Recap: Directory - Where’s my file??",
    "text": "Recap: Directory - Where’s my file??\n\nR Project\nWe will be going over using the R Project in class, but in case there are still some lingering questions, these resources are extremely helpful.\n&lt;https://uopsych.github.io/psy611/labs/lab-1.html#projects&gt;   &lt;https://martinctc.github.io/blog/rstudio-projects-and-working-directories-a-beginner%27s-guide/&gt; \nA directory refers to a file path (location on your computer). A working directory in R is the default file path where R will read and save files. You can check your current working directory by typing getwd() in the console.\ngetwd()  [1] \"C:/Users/Dustin_Haraden/Documents\"\nBecause I am working on a PC, subfolders are separated by \\. Alternatively, if you use a Mac, subfolders will be separated by /.\nSince we are going to be using the here() package, this will update the default file path from what you get above to where you have opened your R-Notebook. Basically you are telling R, “Hey! Look right here where I opened this file. I want you to stay right here and not wander off to another part of my computer. If you do, I will be very sad. Please don’t do that to me.” \nWhenever starting a new project/analysis, it will be helpful to create a different folder to include all of the information. This folder will also have your R Project file to again, inform A sample of this could be something like this:",
    "crumbs": [
      "Additional Stuff"
    ]
  },
  {
    "objectID": "resources.html#create-a-reproducible-lab-report",
    "href": "resources.html#create-a-reproducible-lab-report",
    "title": "Resources",
    "section": "Create a reproducible lab report",
    "text": "Create a reproducible lab report\nTo create your new lab report, in RStudio, go to New File -&gt; R Markdown. Then delete everything after Line 5 and save it in the folder you will be using for the current lab. Remember, make a single folder on your computer that holds everything necessary for the project you are working on.",
    "crumbs": [
      "Additional Stuff"
    ]
  },
  {
    "objectID": "resources.html#put-the-data-where-it-needs-to-be",
    "href": "resources.html#put-the-data-where-it-needs-to-be",
    "title": "Resources",
    "section": "Put the Data where it needs to be",
    "text": "Put the Data where it needs to be\nDownload your data that you will be using and place this data file in the folder you are using. I always encourage a “Data” Folder that holds all raw data.",
    "crumbs": [
      "Additional Stuff"
    ]
  },
  {
    "objectID": "resources.html#load-the-libraries",
    "href": "resources.html#load-the-libraries",
    "title": "Resources",
    "section": "Load the Libraries",
    "text": "Load the Libraries\nGet the libraries loaded in their own code chunk. We will be using here, psych and rio. Remember that if you haven’t already installed these libraries (i.e., bought the book from the book store for your own personal library), you will need to run the command install.packages() in the console with the appropriate packages name in the parentheses surrounded by quotation marks.\nIn the console:\ninstall.packages(\"here\") install.packages(\"tidyverse\") install.packages(\"rio\")\nIn the first code chunk of your Rmd file\nlibrary(here) library(tidyverse) library(rio)",
    "crumbs": [
      "Additional Stuff"
    ]
  },
  {
    "objectID": "resources.html#import-the-data",
    "href": "resources.html#import-the-data",
    "title": "Resources",
    "section": "Import the data",
    "text": "Import the data\nImport the data using the rio package and save it to an object called sleep_data. You will be able to use the import() function as well as the here() function.\n\n\n\n\n\n\nsleep_data &lt;- import(here(“Labs”, “Data”, “SleepFile”, “SleepData.sav”))",
    "crumbs": [
      "Additional Stuff"
    ]
  },
  {
    "objectID": "resources.html#histogram",
    "href": "resources.html#histogram",
    "title": "Resources",
    "section": "Histogram",
    "text": "Histogram\nOne common way of visualizing distributions is using a histogram, which plots the frequencies of different values for a given variable.\nFor example, let’s take a look at a distribution of the age variable. We do this using the hist() function. (Remember, you can check out the help documentation using ?hist).\nCreate a histogram using the age variable with the title “Histogram of Age” and the x-axis labeled as “Age”.\nYou can also change the number of bins (i.e. bars) in your histogram using the breaks argument. Try 5, 10, and 20 breaks. What do you notice as the number of breaks increases?",
    "crumbs": [
      "Additional Stuff"
    ]
  },
  {
    "objectID": "resources.html#boxplot",
    "href": "resources.html#boxplot",
    "title": "Resources",
    "section": "Boxplot",
    "text": "Boxplot\nAnother way to visualize distribution and to better examine the outliers is to use a boxplot. For a short guide on how to read boxplots, seehere or refer tothis section of the textbook.\nCreate a boxplot using the age variable with the title “Boxplot of Age” and the x-axis labeled as “Age”. What do you notice??\nInvestigate the distribution more with boxplot.stats(x = sleep_data$age)$out",
    "crumbs": [
      "Additional Stuff"
    ]
  },
  {
    "objectID": "resources.html#looking-into-the-future",
    "href": "resources.html#looking-into-the-future",
    "title": "Resources",
    "section": "Looking into the future…",
    "text": "Looking into the future…\nSo far we have been plotting in base R. However, theggplot2 package is generally a much better tool for plotting. For now we’ll stick with base plotting to keep things simple, but in a future class you will learn how to use ggplot to make better-looking plots, such as this:\nOk, so now that we know how to visualize a basic distribution, let’s think about how we commonly characterize distributions with descriptive statistics…",
    "crumbs": [
      "Additional Stuff"
    ]
  },
  {
    "objectID": "resources.html#measures-of-central-tendency",
    "href": "resources.html#measures-of-central-tendency",
    "title": "Resources",
    "section": "Measures of Central Tendency",
    "text": "Measures of Central Tendency\nFor a given set of observations, measures of central tendency allow us to get the “gist” of the data. They tell us about where the “average” or the “mid-point” of the data lies. Let’s take a look at the data that we have already loaded in, and complete some of these tasks (which we may already have done in previous classes). \n\nMean\nA quick way to find the mean is to use the aptly named mean() function from base R. Use this function on the age variable in the sleep_data dataset.\n\n\n\nmean(sleep_data$age)\n\n\n\nOh no! We forgot to account for the missing variables in our variable! We got NA! The reason for this is that the mean is calculated by using every value for a given variable, so if you don’t remove (or impute) the missing values before getting the mean, it won’t work.\nLet’s try that again, but using the additional argument to eliminate (or remove) the NA’s from the variable prior to computing the mean. \n\n\n\nmean(sleep_data$age, na.rm = TRUE)\n\n\n\n\n\nMedian\nThe median is the middle value of a set of observations: 50% of the data points fall below the median, and 50% fall above.\nTo find the median, we can use the median() function. Use it on the age variable.",
    "crumbs": [
      "Additional Stuff"
    ]
  },
  {
    "objectID": "resources.html#measures-of-variability",
    "href": "resources.html#measures-of-variability",
    "title": "Resources",
    "section": "Measures of Variability",
    "text": "Measures of Variability\n\nRange\nThe range gives us the distance between the smallest and largest value in a dataset. You can find the range using the range() function, which will output the minimum and maximum values. Find the range of the age variable.\n\n\nVariance and Standard Deviation\nTo find the variance and standard deviation, we use var() and sd(), respectively. Find the variance and standard deviation of the age variable.",
    "crumbs": [
      "Additional Stuff"
    ]
  },
  {
    "objectID": "resources.html#describe",
    "href": "resources.html#describe",
    "title": "Resources",
    "section": "describe()",
    "text": "describe()\nThis function automatically calculates all of the descriptives we reviewed above (and more!). Use the describe() function from the psych package on the entire sleep_data dataset.\nNotes: If you load a library at the beginning, you can directly call any function from it. Instead, you can call a function by library_name::function_name without loading the entire library.\n\n\n\n\n\n\npsych::describe(sleep_data)\n# or if you have already loaded the library\ndescribe(sleep_data)\n\n\n\nNOTE: Some variables are not numeric and are categorical variables of type character. By default, the describe() function forces non-numeric variables to be numeric and attempts to calculate descriptives for them. These variables are marked with an asterisk (*). In this case, it doesn’t make sense to calculate descriptive statistics for these variables, so we get a warning message and a bunch of NaN’s and NA’s for these variables.\nA better approach would be to remove non-numeric variables before you attempt to run numerical calculations on your dataset.\nNow let’s take a closer look at trying to update the age variable in this dataset.",
    "crumbs": [
      "Additional Stuff"
    ]
  },
  {
    "objectID": "resources.html#what-is-data-wrangling",
    "href": "resources.html#what-is-data-wrangling",
    "title": "Resources",
    "section": "What is data wrangling?",
    "text": "What is data wrangling?\nData wrangling, broadly speaking, means getting your data into a useful form for visualizing and modeling it. Hadley Wickham, who has developed a lot of the tidyverse, conceptualizes the main steps involved in data wrangling as follows:\n\nImporting your data \nTidying your data (see brief overview below)\nTransforming your data (what we’ll cover today)\n\nThe figure below highlights the steps in data wrangling in relation to the broader scope of a typical data science workflow:",
    "crumbs": [
      "Additional Stuff"
    ]
  },
  {
    "objectID": "resources.html#what-is-tidy-data",
    "href": "resources.html#what-is-tidy-data",
    "title": "Resources",
    "section": "What is “tidy data”?",
    "text": "What is “tidy data”?\nData is considered “tidy” when: \n\nEach variable has its own column\nEach observation has its own row\nEach value has its own cell\n\nThe following figure is from R for Data Science and visualizes tidy data. \nIf your data is not already in tidy format when you import it, you can use functions from the {tidyR} package, e.g. pivot_longer() and pivot_wider(), that allow you to “reshape” your data to get it into tidy format.\nHowever, this term we are mostly going to work with simpler datasets that are already tidy, so we are not going to focus on these functions today. These functions will become especially useful in the future when we work with repeated measures data that has multiple observations for each subject. If you are interested in learning more about reshaping your data with {tidyR}, check out this chapter from R for Data Science.",
    "crumbs": [
      "Additional Stuff"
    ]
  },
  {
    "objectID": "resources.html#pipes",
    "href": "resources.html#pipes",
    "title": "Resources",
    "section": "Pipes",
    "text": "Pipes\nPipes come from the {magrittr} package are available when you load the tidyverse. (Technically, the pipe is imported with {dplyr}.) Pipes are a way to write strings of functions more easily, creating pipelines. They are extremely powerful and useful. A pipe looks like this:\nYou can enter a pipe with the shortcut CTRL+Shift+M for PC or CMD+Shift+M for Mac.\nA pipe passes an object on the left-hand side as the first argument (or . argument) of whatever function is on the right-hand side.\n\nx %&gt;% f(y) is the same as f(x, y)\ny %&gt;% f(x, ., z) is the same as f(x, y, z )\n\nExample: I want to calculate the mean of the mpg variable from the mtcars data set and round our answer to 2 decimal places. I can accomplish this by nesting:\n\n\n\nround(mean(mtcars$mpg, na.rm = TRUE), 2)\n\n\n\nOr, we could use pipes. Grammatically, you can think of a pipe as “then.” I have a variable, the mile per gallon of cars, THEN I want to take the mean of that variable, and THEN I want to round that answer to two decimal places.\n\n\n\n\n\n\nmtcars$mpg %&gt;% # select the `mpg` variable from the `mtcars` dataset\nmean(na.rm = TRUE) %&gt;% # calculate the mean\nround(2) # round to 2 decimal places\n\n\n\nNow try rewriting the following code using pipes:\n\n\n\nround(sqrt(sum(mtcars$cyl)), 1)\n\n\n\n\nWhy use pipes?\n\nCleaner code\n\nThis is nice, because it helps make your code more readable by other humans (including your future self).\n\n\n\n\nCleaner environment\n\nWhen you use pipes, you have basically no reason to save objects from intermediary steps in your data wrangling / analysis workflow, because you can just pass output from function to function without saving it.\nFinding objects you’re looking for is easier.\n\n\n\n\nEfficiency in writing code\n\nNaming objects is hard; piping means coming up with fewer names.\n\n\n\n\nMore error-proof\n\nBecause naming is hard, you might accidentally re-use a name and make an error.",
    "crumbs": [
      "Additional Stuff"
    ]
  },
  {
    "objectID": "resources.html#manipulating-observations",
    "href": "resources.html#manipulating-observations",
    "title": "Resources",
    "section": "Manipulating Observations",
    "text": "Manipulating Observations\n\nExtract rows with filter()\nThe filter() function is used to subset observations based on their values. The result of filtering is a data frame with the same number of columns as before but fewer rows, as illustrated below…\nThe first argument is data and subsequent arguments are logical expressions that tell you which observations to retain in the data frame.\nFor example, we can filter rows to retain data only for the students who do not have a roommate.\n\n\n\n\n\n\nsleep_data %&gt;%\nfilter(roommate == 2)\n\n\n\nBut we may want to save this as a new datafile. Can assign this to a new object.\n\n\nLogical Operators\nThe == we just used is an example of a comparison operator that tests for equality. The other comparison operators available are :\n\n&gt; (greater than)\n&gt;= (greater than or equal to)\n&lt; (less than)\n&lt;= (less than or equal to)\n!= (not equal to)\n\nYou can combine multiple arguments to filter() with Boolean operators. The figure below fromR for Data Science shows the complete set of Boolean operators.\n\n\nTry it out yourself: \nFirst, let’s filter for observations that are greater than the mean of age\n\n\n\n\n\n\nsleep_data %&gt;%\nfilter(age &gt; mean(age, na.rm = TRUE)\n\n\n\nNow, you try filtering observations that are greater than the mean of happiness, but the participant does have a roommate: \n\n\n\n# Put your code here\n\n\n\nFilter out the age variable that are out of bounds",
    "crumbs": [
      "Additional Stuff"
    ]
  },
  {
    "objectID": "resources.html#manipulating-variables",
    "href": "resources.html#manipulating-variables",
    "title": "Resources",
    "section": "Manipulating Variables",
    "text": "Manipulating Variables\n\nExtract columns with select()\nThe select() function subsets columns in your data frame. This is particularly useful when you have a data set with a huge number of variables and you want to narrow down to the variables that are relevant for your analysis.\nThe first argument is data, followed by the name(s) of the column(s) you want to subset. Note that you can use variable positions rather than their names, but this is usually not as useful. Let’s go through some simple examples of common uses of select().\nSelect one variable\n\n\n\n\n\n\nsleep_data %&gt;%\nselect(bed_study)\n\n\n\nSelect multiple variables\n\n\n\n\n\n\nsleep_data %&gt;%\nselect(bed_study, bed_read, bed_friends)\n\n\n\nSelect a range of variables\n\n\n\n\n\n\nsleep_data %&gt;%\nselect(bed_study:bed_videogames) %&gt;%\nnames()\n\n\n\nDe-select variables with a minus sign (-)\n\n\n\n\n\n\nsleep_data %&gt;%\nselect(-age)\n\n\n\nDe-select range of variables\nNote: everything() is a helper function that gives us all the remaining variables in the data frame (see more onhelper functions below)\n\n\n\n\n\n\nsleep_data %&gt;%\nselect(-(ESS1:everything())\n\n\n\n\n\nHelper functions for select()\nThere are some “helper” functions that you can use along with select() that can sometimes be more efficient than selecting your variables explicitly by name.\n\n\n\n\n\n\n\nfunction\nwhat it does\n\n\nstarts_with()\nselects columns starting with a string\n\n\nends_with()\nselects columns that end with a string\n\n\ncontains()\nselects columns that contain a string\n\n\nmatches()\nselects columns that match a regular expression\n\n\nnum_ranges()\nselects columns that match a numerical range\n\n\none_of()\nselects columns whose names match entries in a character vector\n\n\neverything()\nselects all columns\n\n\nlast_col()\nselects last column; can include an offset.\n\n\n\nQuick example:\n\n\n\n\n\n\nsleep_data %&gt;%\nselect(starts_with(“a”)\n\n\n\n\n\nMake new variables with mutate()\nThe mutate() function is most commonly used to add new columns to your data frame that are functions of existing columns.\nmutate() requires data as its first argument, followed by a set of expressions defining new columns. Let’s take a couple examples…\nCreate new variables\n\nNote: New variables are automatically added at the end of the data frame (scroll to the right to see them)\n\n\n\n\n\n\n\nsleep_data &lt;- sleep_data %&gt;%\nmutate(ess_sum = ESS1 + ESS2 + ESS3 + ESS4 +\nESS5 + ESS6 + ESS7 + ESS8)",
    "crumbs": [
      "Additional Stuff"
    ]
  },
  {
    "objectID": "activities/basic_intro.html",
    "href": "activities/basic_intro.html",
    "title": "Getting Comfy with R",
    "section": "",
    "text": "In-Class Activity: Your First R Session\nGoal: To become familiar with the RStudio interface and perform a basic data exploration workflow.\n\n\nCreate a new Markdown Document\n\nGo to File &gt; New File &gt; R Markdown\nProvide a title and input your name as the author\nA script will open in the Source pane. Remove unnecessary code.\nGo to File &gt; Save and name it introduction.Rmd. Make sure this saves in the same folder as all of your other stuff (i.e., wherever the project is). Stay Organized!\n\nI’m not going to tell you how to organize your folders, but I will give a suggestion. Have 1 folder for the whole class. This will have the Project that we created. Inside there, have a folder for “Class Activities”. This is where you can save this file. Then, have other folders for the labs and what not.\n\n\n\n\nYour First “Analysis”\n\nCreate a Code Chunk\nLoad the tidyverse library\nCreate the object datawars and assign dataset called starwars to it (hint: data &lt;- cars)\nUse View(), head() and glimpse() to look at datawars\nIn the text below, answer these questions:\n\nWhat do each of these do?\nWhich do you like more?\n\nCreate another code chunk and use summary() to get descriptives of all variables in the dataset.\n\nLook at the output of your summary() command. For the mass and height variables, you’ll see a value for NA's. In your own words, what do you think NA means in this context?\n\n\n\nVisualize your data\nNow we want to investigate the relationship between mass and height in this dataset.\n\nCreate a scatterplot using ggplot().\nThe plot should show height on the x-axis and mass on the y-axis.\nAdd some labels to make your plot clear and professional.\n\nHint: Use the code below as a template and fill in the blanks.\n\n\nggplot(data = __, aes(x = __, y = __)) +\n  geom_point() +\n  labs(title = \"__\",\n       x = \"__\",\n       y = \"__\")\n\nLook at your plot. Do you notice any characters that seem unusually heavy for their height? Briefly describe one.\n\n\n\nWrangle your Data\nSince we have some outliers that seem to be related to non-human species, let’s just look at Humans.\n\nCreate a new object called rebels.\nThis new object should contain only the characters from the starwars dataset where the species is “Human”.\n\nHint: Use the filter() function. The syntax is new_object &lt;- old_object %&gt;% filter(column_name == \"value\"). Remember that “Human” needs to be in quotes.\n\nPrint your new rebels object to the console to make sure your filter worked correctly. Once confirmed, calculate the average (hint: use mean()) for the height and weight of the rebels.\n\n\nHow many rows are in your new rebels dataset?\nWhat is the average height and weight?\n\n\nCreate another scatterplot with your new dataset. Copy and update the code we used previously.\n\nEnd of the document. Try knitting🧶 the document!"
  },
  {
    "objectID": "activities/data-wrangling-origin.html",
    "href": "activities/data-wrangling-origin.html",
    "title": "Data Wrangling Origin",
    "section": "",
    "text": "We are going to keep practicing the skills we started in the last session. Before, we were using pre-installed data, but that won’t be the case IRL. When working with your own data, you will want to create a workflow of cleaning and wrangling your data in a reproducible way. These steps will likely occur for every new dataset that you work with.\nPlease complete the exercises below. Create a new .Rmd file and include the following at the top:\n---\ntitle: \"Data Wrangling Origins\"\nauthor: \"Your Name Here\"\ndate: \"`r Sys.Date()`\"\noutput: html_document\neditor_options: \n  chunk_output_type: console\n  markdown: \n    wrap: 72\n---\nYou should be able to follow along, but if you want a template Markdown, download it below.\n\nDownload Markdown (.Rmd)"
  },
  {
    "objectID": "activities/data-wrangling-origin.html#instructions",
    "href": "activities/data-wrangling-origin.html#instructions",
    "title": "Data Wrangling Origin",
    "section": "",
    "text": "We are going to keep practicing the skills we started in the last session. Before, we were using pre-installed data, but that won’t be the case IRL. When working with your own data, you will want to create a workflow of cleaning and wrangling your data in a reproducible way. These steps will likely occur for every new dataset that you work with.\nPlease complete the exercises below. Create a new .Rmd file and include the following at the top:\n---\ntitle: \"Data Wrangling Origins\"\nauthor: \"Your Name Here\"\ndate: \"`r Sys.Date()`\"\noutput: html_document\neditor_options: \n  chunk_output_type: console\n  markdown: \n    wrap: 72\n---\nYou should be able to follow along, but if you want a template Markdown, download it below.\n\nDownload Markdown (.Rmd)"
  },
  {
    "objectID": "activities/data-wrangling-origin.html#scenario-and-goal",
    "href": "activities/data-wrangling-origin.html#scenario-and-goal",
    "title": "Data Wrangling Origin",
    "section": "Scenario and Goal",
    "text": "Scenario and Goal\nCongratulations, you’ve just collected data for a study on “Personality”! You administered a 10-item personality questionnaire, where participants responded on a 5-point Likert scale (1 = Strongly Disagree, 5 = Strongly Agree). This measure is called the “Ten Item Personality Inventory” (TIPI) and more information about the measure can be found here: TIPI Scale Info. Please refer to this page and documents to help with scoring the data and getting familiar with the measure.\nHowever, the raw data from the survey software is messy. Your goal in this lab is to import, clean, and score the data to prepare it for analysis. This process of turning raw data into usable data is called data wrangling, and it’s what researchers spend most of their time doing.\nYou will learn to: * Import a CSV file. * Rename variables for clarity. * Filter out participants based on data quality checks. * Reverse-score negatively worded items. * Compute a composite score for a psychological scale.\n\n\nGetting Data\nBe aware of your file structure and how things are organized. For some refreshers, take a look at the Resources and rstats.wtf\n\nDownload your data (Materials)\n\n\n\nExercise 1: Importing and Inspecting the Data\nFirst, you need to load the appropriate packages and import your data. Use the tidyverse, rio, and here libraries.\n# Load the appropriate libraries.   \n\n# Write your import code here:   \n  ## This will look like:     \n  # your_data_name &lt;- import(here(\"path\", \"to\", \"file\", \"filename.csv))    \n\n\n# Use glimpse() to get a first look at the raw_data. \n# Write your code here:  \nQuestion 1: How many participants (rows) are in the raw, imported dataset?\n❓Your Answer: [Type your answer here]\n\n\n\nExercise 2: Renaming Variables for Clarity\nThe column names are a mixture of naming conventions. Let’s rename them to be consistent and convey the appropriate information.\nFirst, let’s take a look at what the names are. You can do this by using View(), but let’s use the names() function to list out all the column names.\nnames(Whatever_you_Named_your_data)\nThis will give you your list of names. You can see which ones we may want to rename. What does Q85 even mean? Thanks Qualtrics. Review the documentation for the survey to get a sense of what the questions are asking to properly rename the variables.\nFor now, let’s update the names as follows. It is helpful to keep everything lowercase to make it easier to type (but this is a personal preference), and make sure there aren’t any spaces in your variable names:\n\nID -&gt; id\nProgress -&gt; progress\nDuration (in seconds) -&gt; duration\nConsent -&gt; consent\nQ85 -&gt; sex_orient\nQ85_6_TEXT -&gt; sex_orient_txt\nSleep Quality -&gt; sleep_qual\nHours of Sleep -&gt; sleep_hours\n\n# Task: Use the rename() function to change the variable names as listed above.\n# Create a new object called `renamed_data`.\n# Hint: The syntax is: new_object &lt;- old_object %&gt;% rename(new_name_1 = old_name_1, new_name_2 = old_name_2)\n\n# Write your code here:\n# This part is a placeholder as the actual column names from the URL will differ.\n# Be sure to update the following template with the info from your own data\nrenamed_data &lt;- raw_data %&gt;%\n  rename(participant_id = country, \n         grit_1 = year,\n         grit_2 = population)\n         # ... and so on for the other variables\n\n# Print the first few rows of your new `renamed_data` object to check your work.\nhead(renamed_data)\n\n\n\nExercise 3: Filtering for Data Quality\nOur survey includes variables that allow us to see how long they took and what percentage they completed. We should remove participants who did not finish the survey, as well as those who finished it too quickly.\nThis will be done using the filter() function (more about filter). Use filter to keep participants where their progress is equal to 100. You will also want to remove participants who completed the survey in less than 7 minutes (note: the Duration variable is in seconds).\n# Create a new object called `filtered_data`.\n\n# Example code:\n# filtered_data &lt;- renamed_data %&gt;%\n#   filter(Progress == 100) %&gt;% \n#   filter(Duration ==, &lt;, &gt; 1000)\nQuestion 2: How many participants remain from your original dataset? How many participants did you remove with your filters?\n❓Your Answer: [Type your answer here]\n\n\n\nExercise 4: Reverse-Scoring Items\nIn a lot of psychological research, we need to reverse score variables. They are often worded in a negative/positive way compared to the rest of the items. Review the TIPI documentation to see what items need to be reverse scored.\nFor example, Item 2 is a item that should reflect “Agreeableness”, but the rated words are “Critical, quarrelsome”. Therefore low score on this item would reflect high amounts of Agreeableness.\nThe formula for reverse scoring an item is: (Maximum Possible Value + 1) - Original Score. So, for the TIPI, it’s 8 - TIPI_2.\nTo create/compute a new variable we use the mutate() function (more about mutate). I like to remember this function name because we are “mutating” the data and introducing another “growth” or something extra that wasn’t there before.\n# Task: Use the mutate() function to create new, reverse-scored variables.\n# Use a new name to indicate which items are reverse-scored.\n# Create a new object called `scored_data`.\n# Hint: The syntax is: \n  # new_object &lt;- old_object %&gt;% \n  #   mutate(new_variable = computation, \n  #          new_variable2 = computation)\n\n\n# Exmple code:\n# scored_data &lt;- filtered_data %&gt;%\n#   mutate(TIPI_2r = 8 - TIPI_2)\n\n\n\n# Print the first few rows, showing only the original and new reverse-scored item to check your work.\n\n# scored_data %&gt;% select(TIPI_2, TIPI_2r) %&gt;% head()\nQuestion 3: If a participant’s original score on TIPI_4 was a 6, what would their score be on the new TIPI_4r variable?\n❓Your Answer: [Type your answer here]\n\n\n\nExercise 5: Computing and Finalizing the Scored File\nNow we are ready to compute the final score! There are individual subscales for each of the 5 factors of the Big 5 Personality Inex. Compute the 5 scales. Remember to use the reverse-scored items (TIPI_2r), not the original one.s\n# Task 1: Use mutate() to calculate the total grit score.\n# Sum the items corresponding to each scale.\n# Call the new variables 'extra', 'agree', 'consc', 'emo', 'open.\n# Overwrite your `scored_data` object with this new version.\n\n# Task 2: Create a final, clean dataset.\n# Use select() to keep only the 'id' and Big 5 scale columns.\n# Call this object `final_data`.\n# Conceptual code:\n# final_data &lt;- scored_data %&gt;%\n#   select(id, agree, ...)\n\n\n\n# Task 3: Calculate the mean and standard deviation of each of the subscale scores.\nQuestion 4: What would be the highest possible Emotional Stability score a participant could get? What would be the lowest?\n❓Your Answer: [Type your answer here]\nQuestion 5: Report the mean’s and standard deviations of each of the subscale scores\n❓Your Answer:\n\nExtraversion:\nAgreeableness:\nConscientiousness:\nEmotional Stability:\nOpenness to Experience:\n\n\n\n\nExercise 6: Visualize Relationships\nWe often want to see the relationship between 2 variables. This is often done using a scatterplot. Select 2 scales that you would like to see the relationship between. Use the code from the previous lab/class to create a scatterplot of the relationship. Take a look at this cheat sheet to help with ggplot2!\n# Using ggplot and the scored data you have, generate a scatterplot. It can be as simple or as fancy as you would like (try putting a title and changing the axis names)\n\n\n\n# Use the cheat sheet and other materials to put a straight line to the data (Hint: add another layer with a smooth geom)\nQuestion 6.1: Visually inspect the chart you have and describe the relationship below. Be sure to include the two variables and an estimate of your correlation in your answer.\n❓Your Answer:\n# Compute a correltion for your variables\n# Hint: use the `cor.test()` function. You will need to specify the variable names as `name_of_data$name_of_variable`\n  \n  # Example\n    # cor.test(starwars$height, starwars$mass)\nQuestion 6.2: Calculate the correlation coefficient for your two variables of interest (refer here for more info). Report the correlation, and reflect on how close or how far away your initial estimate was. Do your best here. I recognize that we haven’t really gone over this just yet.\n❓Your Answer:\n\nEnd of Lab. Don’t forget to Knit! 🧶"
  },
  {
    "objectID": "weeks/week-4.html",
    "href": "weeks/week-4.html",
    "title": "Week 4",
    "section": "",
    "text": "💻 Getting Started - Syllabus\n💻Getting Started - Data\n\n\n\nGetting Comfy with R\n\n\n\n📋Lab 1 - Foundations of a Data Workflow\n📖Read Chapter 1 & 2 - ST\n📖Read Chapter 2 - MSR\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-4.html#slides",
    "href": "weeks/week-4.html#slides",
    "title": "Week 4",
    "section": "",
    "text": "💻 Getting Started - Syllabus\n💻Getting Started - Data"
  },
  {
    "objectID": "weeks/week-4.html#in-class-activity",
    "href": "weeks/week-4.html#in-class-activity",
    "title": "Week 4",
    "section": "",
    "text": "Getting Comfy with R"
  },
  {
    "objectID": "weeks/week-4.html#for-next-time",
    "href": "weeks/week-4.html#for-next-time",
    "title": "Week 4",
    "section": "",
    "text": "📋Lab 1 - Foundations of a Data Workflow\n📖Read Chapter 1 & 2 - ST\n📖Read Chapter 2 - MSR\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-2.html",
    "href": "weeks/week-2.html",
    "title": "Week 2",
    "section": "",
    "text": "You survived the first week! I hope your classes are off to a good start. Although we don’t have class this week (Labor Day), we will still have readings and an assignment. Please view this page to make sure you have all the information you need to get going.\nWe are going to work on expanding our comfort with the syntax in R and using the tidyverse for some more data wrangling. We will import some new data, and compute some new values. This will be a skill that will be useful no matter what data you are working with. There will be plenty of practice with this!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n“Illustrations from the Openscapes blog Tidy Data for reproducibility, efficiency, and collaboration by Julia Lowndes and Allison Horst”\n\n\n\nBe sure to have read the chapters!\nDownload the data for this week\n\nDownload From Drive (CSV)\n\n\n\nNone (Labor Day)\n\n\n\nNo Class this week (Labor Day)\n\n\n\n📋Lab 2 - Getting Comfy with Data Wrangling\n📖Read Chapter 5 - LSR\n📖Read Chapter 1 & 3 - R4DS\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-2.html#prepare",
    "href": "weeks/week-2.html#prepare",
    "title": "Week 2",
    "section": "",
    "text": "Be sure to have read the chapters!\nDownload the data for this week\n\nDownload From Drive (CSV)"
  },
  {
    "objectID": "weeks/week-2.html#slides",
    "href": "weeks/week-2.html#slides",
    "title": "Week 2",
    "section": "",
    "text": "None (Labor Day)"
  },
  {
    "objectID": "weeks/week-2.html#in-class-activity",
    "href": "weeks/week-2.html#in-class-activity",
    "title": "Week 2",
    "section": "",
    "text": "No Class this week (Labor Day)"
  },
  {
    "objectID": "weeks/week-2.html#for-next-time",
    "href": "weeks/week-2.html#for-next-time",
    "title": "Week 2",
    "section": "",
    "text": "📋Lab 2 - Getting Comfy with Data Wrangling\n📖Read Chapter 5 - LSR\n📖Read Chapter 1 & 3 - R4DS\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "topics/tab-mark.html",
    "href": "topics/tab-mark.html",
    "title": "Tables & Reporting",
    "section": "",
    "text": "We are going to explore some of the useful libraries to report tables in R, and try to capitalize on how R knits information. The goal is to have all analyses and the text in a single document that will update as necessary.\nThere won’t be any slides with this one, we will just work on doing some coding together!\nLet’s start with a new file and adding in a new dataset. It is good to continuously check to make sure that your code is reproducible by closing your project often or restarting R.\nDark R’s Dark Rs (.Rmd)\nWhen starting a file, I like to have all libraries and setup in the initial block. This makes sure that everything is covered and whenever I share this file, those receiving it will be aware of how to get started.\n\nlibrary(here) #relative file path\n\nhere() starts at /home/runner/work/aware-stats_2025/aware-stats_2025\n\nlibrary(rio) #import data\nlibrary(easystats) #collection of tools\n\n# Attaching packages: easystats 0.7.5\n✔ bayestestR  0.17.0   ✔ correlation 0.8.8 \n✔ datawizard  1.2.0    ✔ effectsize  1.0.1 \n✔ insight     1.4.2    ✔ modelbased  0.13.0\n✔ performance 0.15.1   ✔ parameters  0.28.1\n✔ report      0.6.1    ✔ see         0.11.0\n\nlibrary(dplyr) #data wrangling\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2) #data visualization\nlibrary(psych) #cronbach alpha (and a whole lot of other stuff)\n\n\nAttaching package: 'psych'\n\n\nThe following objects are masked from 'package:ggplot2':\n\n    %+%, alpha\n\n\nThe following object is masked from 'package:effectsize':\n\n    phi\n\n\nThe following object is masked from 'package:datawizard':\n\n    rescale\n\nlibrary(janitor) #cleaning variable names\n\n\nAttaching package: 'janitor'\n\n\nThe following object is masked from 'package:insight':\n\n    clean_names\n\n\nThe following objects are masked from 'package:datawizard':\n\n    remove_empty, remove_empty_rows\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(sjPlot) #making nice tables\nlibrary(broom)\n\n#tell R not to display scientific notation\noptions(scipen=999)\n\n# Create a list of citations of the libraries that are used\nreport::cite_packages()\n\n  - Ben-Shachar MS, Lüdecke D, Makowski D (2020). \"effectsize: Estimation of Effect Size Indices and Standardized Parameters.\" _Journal of Open Source Software_, *5*(56), 2815. doi:10.21105/joss.02815 &lt;https://doi.org/10.21105/joss.02815&gt;, &lt;https://doi.org/10.21105/joss.02815&gt;.\n  - Chan C, Leeper T, Becker J, Schoch D (2023). _rio: A Swiss-army knife for data file I/O_. &lt;https://cran.r-project.org/package=rio&gt;.\n  - Firke S (2024). _janitor: Simple Tools for Examining and Cleaning Dirty Data_. R package version 2.2.1, &lt;https://github.com/sfirke/janitor&gt;.\n  - Lüdecke D (2025). _sjPlot: Data Visualization for Statistics in Social Science_. R package version 2.9.0, &lt;https://CRAN.R-project.org/package=sjPlot&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing and Exploring the Parameters of Statistical Models using R.\" _Journal of Open Source Software_, *5*(53), 2445. doi:10.21105/joss.02445 &lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021). \"performance: An R Package for Assessment, Comparison and Testing of Statistical Models.\" _Journal of Open Source Software_, *6*(60), 3139. doi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Wiernik B, Bacher E, Thériault R, Makowski D (2022). \"easystats: Framework for Easy Statistical Modeling, Visualization, and Reporting.\" _CRAN_. doi:10.32614/CRAN.package.easystats &lt;https://doi.org/10.32614/CRAN.package.easystats&gt;, R package, &lt;https://easystats.github.io/easystats/&gt;.\n  - Lüdecke D, Patil I, Ben-Shachar M, Wiernik B, Waggoner P, Makowski D (2021). \"see: An R Package for Visualizing Statistical Models.\" _Journal of Open Source Software_, *6*(64), 3393. doi:10.21105/joss.03393 &lt;https://doi.org/10.21105/joss.03393&gt;.\n  - Lüdecke D, Waggoner P, Makowski D (2019). \"insight: A Unified Interface to Access Information from Model Objects in R.\" _Journal of Open Source Software_, *4*(38), 1412. doi:10.21105/joss.01412 &lt;https://doi.org/10.21105/joss.01412&gt;.\n  - Makowski D, Ben-Shachar M, Lüdecke D (2019). \"bayestestR: Describing Effects and their Uncertainty, Existence and Significance within the Bayesian Framework.\" _Journal of Open Source Software_, *4*(40), 1541. doi:10.21105/joss.01541 &lt;https://doi.org/10.21105/joss.01541&gt;, &lt;https://joss.theoj.org/papers/10.21105/joss.01541&gt;.\n  - Makowski D, Ben-Shachar M, Wiernik B, Patil I, Thériault R, Lüdecke D (2025). \"modelbased: An R package to make the most out of your statistical models through marginal means, marginal effects, and model predictions.\" _Journal of Open Source Software_, *10*(109), 7969. doi:10.21105/joss.07969 &lt;https://doi.org/10.21105/joss.07969&gt;, &lt;https://joss.theoj.org/papers/10.21105/joss.07969&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023). \"Automated Results Reporting as a Practical Tool to Improve Reproducibility and Methodological Best Practices Adoption.\" _CRAN_. &lt;https://easystats.github.io/report/&gt;.\n  - Makowski D, Wiernik B, Patil I, Lüdecke D, Ben-Shachar M (2022). \"correlation: Methods for Correlation Analysis.\" Version 0.8.3, &lt;https://CRAN.R-project.org/package=correlation&gt;. Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020). \"Methods and Algorithms for Correlation Analysis in R.\" _Journal of Open Source Software_, *5*(51), 2306. doi:10.21105/joss.02306 &lt;https://doi.org/10.21105/joss.02306&gt;, &lt;https://joss.theoj.org/papers/10.21105/joss.02306&gt;.\n  - Müller K (2020). _here: A Simpler Way to Find Your Files_. R package version 1.0.1, &lt;https://here.r-lib.org/&gt;.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022). \"datawizard: An R Package for Easy Data Preparation and Statistical Transformations.\" _Journal of Open Source Software_, *7*(78), 4684. doi:10.21105/joss.04684 &lt;https://doi.org/10.21105/joss.04684&gt;.\n  - R Core Team (2025). _R: A Language and Environment for Statistical Computing_. R Foundation for Statistical Computing, Vienna, Austria. &lt;https://www.R-project.org/&gt;.\n  - Robinson D, Hayes A, Couch S (2025). _broom: Convert Statistical Objects into Tidy Tibbles_. R package version 1.0.9, &lt;https://broom.tidymodels.org/&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_. Springer-Verlag New York. ISBN 978-3-319-24277-4, &lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar of Data Manipulation_. R package version 1.1.4, &lt;https://dplyr.tidyverse.org&gt;.\n  - William Revelle (2025). _psych: Procedures for Psychological, Psychometric, and Personality Research_. Northwestern University, Evanston, Illinois. R package version 2.5.6, &lt;https://CRAN.R-project.org/package=psych&gt;.\n\n# Identify the version of R and the type of machine that is running it\nreport::report_system()\n\nAnalyses were conducted using the R Statistical language (version 4.5.1; R Core\nTeam, 2025) on Ubuntu 24.04.3 LTS\n\n# Create a list of the package names and the in-text citation \n#report::report_packages()\n\n# Import the data\n\ncah &lt;- import(here(\"files\", \"data\", \"CAH_Data.csv\")) %&gt;% \n  clean_names()\n\ntipi &lt;- import(here(\"files\", \"data\", \"final_tipi.csv\"))\n\nThese data are coming from a dataset curated by Cards Against Humanity and their “Pulse of the Nation” survey. You can find more data here.\n\n\nSometimes there will be a data visualization that is needed or even some tables of descriptives. When generating tables, I tend to prefer to use sjPlot (https://strengejacke.github.io/sjPlot/index.html)\n\ncah %&gt;% \n  describe() %&gt;% \n  tibble::rownames_to_column() %&gt;% \n  select(c(rowname, n, mean, sd)) %&gt;% \n  tab_df(title = \"Table 1 - Descriptive Statistics\")\n\n\nTable 1 - Descriptive Statistics\n\n\nrowname\nn\nmean\nsd\n\n\nid\n1000\n500.50\n288.82\n\n\nincome\n456\n89589.91\n72275.00\n\n\ngender*\n1000\n2.54\n0.56\n\n\nage\n1000\n49.41\n16.63\n\n\nage_range*\n1000\n3.91\n1.55\n\n\npolitical_affiliation*\n1000\n2.63\n0.97\n\n\neducation*\n1000\n3.71\n1.60\n\n\nethnicity*\n1000\n5.04\n1.55\n\n\nmarrital_status*\n1000\n4.71\n1.79\n\n\nclimate_change*\n1000\n2.91\n0.77\n\n\ntransformers\n938\n1.33\n1.56\n\n\nbooks\n977\n22.33\n75.87\n\n\nghosts*\n1000\n2.35\n0.53\n\n\nspending*\n1000\n2.84\n1.12\n\n\nchoice*\n1000\n2.32\n0.65\n\n\nshower_pee*\n1000\n2.40\n0.67\n\n\n\n\n\n\ncah %&gt;% \n  select(c(age, income, books, transformers)) %&gt;% \n  tab_corr(title = \"Table 2 - Correlations\", \n           triangle = \"lower\", \n           var.labels = c(\"Age\", \"Income\", \"# of books\", \"# of Transformers Movies\"))\n\n\nTable 2 - Correlations\n\n\n \nAge\nIncome\n# of books\n# of Transformers Movies\n\n\nAge\n \n \n \n \n\n\nIncome\n-0.068\n \n \n \n\n\n# of books\n0.009\n-0.058\n \n \n\n\n# of Transformers Movies\n-0.212***\n-0.094\n0.093\n \n\n\nComputed correlation used pearson-method with listwise-deletion.",
    "crumbs": [
      "Topics",
      "Tables & Reporting"
    ]
  },
  {
    "objectID": "topics/tab-mark.html#tables---sjplot",
    "href": "topics/tab-mark.html#tables---sjplot",
    "title": "Tables & Reporting",
    "section": "",
    "text": "Sometimes there will be a data visualization that is needed or even some tables of descriptives. When generating tables, I tend to prefer to use sjPlot (https://strengejacke.github.io/sjPlot/index.html)\n\ncah %&gt;% \n  describe() %&gt;% \n  tibble::rownames_to_column() %&gt;% \n  select(c(rowname, n, mean, sd)) %&gt;% \n  tab_df(title = \"Table 1 - Descriptive Statistics\")\n\n\nTable 1 - Descriptive Statistics\n\n\nrowname\nn\nmean\nsd\n\n\nid\n1000\n500.50\n288.82\n\n\nincome\n456\n89589.91\n72275.00\n\n\ngender*\n1000\n2.54\n0.56\n\n\nage\n1000\n49.41\n16.63\n\n\nage_range*\n1000\n3.91\n1.55\n\n\npolitical_affiliation*\n1000\n2.63\n0.97\n\n\neducation*\n1000\n3.71\n1.60\n\n\nethnicity*\n1000\n5.04\n1.55\n\n\nmarrital_status*\n1000\n4.71\n1.79\n\n\nclimate_change*\n1000\n2.91\n0.77\n\n\ntransformers\n938\n1.33\n1.56\n\n\nbooks\n977\n22.33\n75.87\n\n\nghosts*\n1000\n2.35\n0.53\n\n\nspending*\n1000\n2.84\n1.12\n\n\nchoice*\n1000\n2.32\n0.65\n\n\nshower_pee*\n1000\n2.40\n0.67\n\n\n\n\n\n\ncah %&gt;% \n  select(c(age, income, books, transformers)) %&gt;% \n  tab_corr(title = \"Table 2 - Correlations\", \n           triangle = \"lower\", \n           var.labels = c(\"Age\", \"Income\", \"# of books\", \"# of Transformers Movies\"))\n\n\nTable 2 - Correlations\n\n\n \nAge\nIncome\n# of books\n# of Transformers Movies\n\n\nAge\n \n \n \n \n\n\nIncome\n-0.068\n \n \n \n\n\n# of books\n0.009\n-0.058\n \n \n\n\n# of Transformers Movies\n-0.212***\n-0.094\n0.093\n \n\n\nComputed correlation used pearson-method with listwise-deletion.",
    "crumbs": [
      "Topics",
      "Tables & Reporting"
    ]
  },
  {
    "objectID": "topics/tab-mark.html#generate-cronbachs-alpha",
    "href": "topics/tab-mark.html#generate-cronbachs-alpha",
    "title": "Tables & Reporting",
    "section": "Generate Cronbach’s Alpha",
    "text": "Generate Cronbach’s Alpha\n\n## Cronbach's Alpha\n#dat %&gt;% \n#  select(BPAQ_1, BPAQ_2, BPAQ_3, BPAQ_4, BPAQ_5) %&gt;% \n#  psych::alpha()",
    "crumbs": [
      "Topics",
      "Tables & Reporting"
    ]
  },
  {
    "objectID": "topics/tidy-viz.html",
    "href": "topics/tidy-viz.html",
    "title": "Tidy & Visualizations",
    "section": "",
    "text": "We are going to work on expanding our comfort with the syntax in R and using the tidyverse for some more data wrangling. We will import some new data, and compute some new values. This will be a skill that will be useful no matter what data you are working with. There will be plenty of practice with this!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n“Illustrations from the Openscapes blog Tidy Data for reproducibility, efficiency, and collaboration by Julia Lowndes and Allison Horst”\n\n\n💻Wrangling with dplyr\n💻Describe & Visualize\n\n\n\n📋Data Wrangling Origin\n📋Describe & Visualize 1\n📋Describe & Visualize 2\n\n\n\n📋Lab 2 - Getting Comfy with Data Wrangling\n📖Read Chapter 5 - LSR\n📖Read Chapter 1 & 3 - R4DS\n\n\nBack to course schedule ⏎",
    "crumbs": [
      "Topics",
      "dplyr & ggplot2"
    ]
  },
  {
    "objectID": "topics/tidy-viz.html#slides",
    "href": "topics/tidy-viz.html#slides",
    "title": "Tidy & Visualizations",
    "section": "",
    "text": "💻Wrangling with dplyr\n💻Describe & Visualize",
    "crumbs": [
      "Topics",
      "dplyr & ggplot2"
    ]
  },
  {
    "objectID": "topics/tidy-viz.html#activity",
    "href": "topics/tidy-viz.html#activity",
    "title": "Tidy & Visualizations",
    "section": "",
    "text": "📋Data Wrangling Origin\n📋Describe & Visualize 1\n📋Describe & Visualize 2",
    "crumbs": [
      "Topics",
      "dplyr & ggplot2"
    ]
  },
  {
    "objectID": "topics/tidy-viz.html#for-next-time",
    "href": "topics/tidy-viz.html#for-next-time",
    "title": "Tidy & Visualizations",
    "section": "",
    "text": "📋Lab 2 - Getting Comfy with Data Wrangling\n📖Read Chapter 5 - LSR\n📖Read Chapter 1 & 3 - R4DS\n\n\nBack to course schedule ⏎",
    "crumbs": [
      "Topics",
      "dplyr & ggplot2"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AI-PROWIL IRES: Statistics Workshop",
    "section": "",
    "text": "Introductions\nGetting Started with R\nBasic Descriptives and Visualizations\nReproducible tables (correlations & regressions)\nIntegrating stats into text\nPotential Topics:\n\nIntro to Structural Equation Modeling\n\nExploratory Factor Analysis\nConfirmatory Factor Analysis\nPath Analysis\nLatent Growth Curve Models\nRandom Intercept Cross Lagged Panel Model\n\n\n\nTopics may shift based on need of those in attendance.\n\n\n\nMy name is Dustin Haraden and I am an assistant professor at Rochester Institute of Technology in New York, USA. I am a clinical psychologist with a focus on developmental psychopathology. My research centers on investigating circadian rhythms, sleep and pubertal development as risk factors for psychopathology in youth. I received my PhD in Clinical/Community Psychology at the University of Illinois at Urbana-Champaign.\nFeel free to reach out to me after the completion of this workshop! I love talking about R and getting folks more familiar with the awesome tool that it is. Plus, I would love to learn some cool new things.\nSeriously, send me an email.\nPresenter: Dustin Haraden, PhD\nContact: Email - dxhgsh@rit.edu; BlueSky - @dustinharaden.bsky.social\n\n\n\nA foundation in organizing your R projects and combatting informal practices. Introduction and exploration of Open Science within a Clinical/Community framework.\n\n\nThe main goal of this course/workshop is to provide an on-ramp to using R in practice. There will likely be introductions to coding and using the software as well as important functions that are used within a social science perspective. Additionally, a goal is to introduce researchers to effective strategies and practices for organizing their research projects within R. The focus will revolve around promoting Open Science practices as they apply to own interests. I will introduce a workflow within R that will maximize reproducibility and attempt to future proof analyses (take that future Dustin!).\n\n\n\n\n\n\n\nComputer with R & R-studio installed & Updated\nLaughter (WARNING: Instructor will make lame dad jokes)\nCuriosity/Interest\nCoffee, tea, or whatever beverage you prefer at this time\n\n\n\n\n\nLight Saber\nT.A.R.D.I.S./Sonic Screwdriver\nDeLorean\nOne Ring to Rule Them All\n\n\n\n\n\nR for Data Science - Hadley Wickham, https://r4ds.hadley.nz/ (free)\nR Markdown: The Definitive Guide - Yihui Xie, J. J. Allaire, Garrett Grolemund; https://bookdown.org/yihui/rmarkdown/ (free)\nWhat They Forgot to Teach You About R - Jenny Bryan, Jim Hester, Shannon Pileggi, E. David Aja; https://rstats.wtf/ (free)\nAdvanced R - Hadley Wickham, https://adv-r.hadley.nz/ (free)\nThe Seven Deadly Sins of Psychology: A Manifesto for Reforming the Culture of Scientific Practice - Chris Chambers (check it out from the library & give it a read when you can)\nImproving your Statistical Inferences - Daniël Lakens https://lakens.github.io/statistical_inferences/ (free)\nggplot2: Elegant Graphics for Data Analysis - Hadley Wickham, Danielle Navarro & Thomas Lin Pedersen https://ggplot2-book.org/ (free)",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#workshop-outline",
    "href": "index.html#workshop-outline",
    "title": "AI-PROWIL IRES: Statistics Workshop",
    "section": "",
    "text": "Introductions\nGetting Started with R\nBasic Descriptives and Visualizations\nReproducible tables (correlations & regressions)\nIntegrating stats into text\nPotential Topics:\n\nIntro to Structural Equation Modeling\n\nExploratory Factor Analysis\nConfirmatory Factor Analysis\nPath Analysis\nLatent Growth Curve Models\nRandom Intercept Cross Lagged Panel Model\n\n\n\nTopics may shift based on need of those in attendance.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#who-is-presenting",
    "href": "index.html#who-is-presenting",
    "title": "AI-PROWIL IRES: Statistics Workshop",
    "section": "",
    "text": "My name is Dustin Haraden and I am an assistant professor at Rochester Institute of Technology in New York, USA. I am a clinical psychologist with a focus on developmental psychopathology. My research centers on investigating circadian rhythms, sleep and pubertal development as risk factors for psychopathology in youth. I received my PhD in Clinical/Community Psychology at the University of Illinois at Urbana-Champaign.\nFeel free to reach out to me after the completion of this workshop! I love talking about R and getting folks more familiar with the awesome tool that it is. Plus, I would love to learn some cool new things.\nSeriously, send me an email.\nPresenter: Dustin Haraden, PhD\nContact: Email - dxhgsh@rit.edu; BlueSky - @dustinharaden.bsky.social",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#workshop-description",
    "href": "index.html#workshop-description",
    "title": "AI-PROWIL IRES: Statistics Workshop",
    "section": "",
    "text": "A foundation in organizing your R projects and combatting informal practices. Introduction and exploration of Open Science within a Clinical/Community framework.\n\n\nThe main goal of this course/workshop is to provide an on-ramp to using R in practice. There will likely be introductions to coding and using the software as well as important functions that are used within a social science perspective. Additionally, a goal is to introduce researchers to effective strategies and practices for organizing their research projects within R. The focus will revolve around promoting Open Science practices as they apply to own interests. I will introduce a workflow within R that will maximize reproducibility and attempt to future proof analyses (take that future Dustin!).",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#workshop-materials",
    "href": "index.html#workshop-materials",
    "title": "AI-PROWIL IRES: Statistics Workshop",
    "section": "",
    "text": "Computer with R & R-studio installed & Updated\nLaughter (WARNING: Instructor will make lame dad jokes)\nCuriosity/Interest\nCoffee, tea, or whatever beverage you prefer at this time\n\n\n\n\n\nLight Saber\nT.A.R.D.I.S./Sonic Screwdriver\nDeLorean\nOne Ring to Rule Them All",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#recommended-future-readings",
    "href": "index.html#recommended-future-readings",
    "title": "AI-PROWIL IRES: Statistics Workshop",
    "section": "",
    "text": "R for Data Science - Hadley Wickham, https://r4ds.hadley.nz/ (free)\nR Markdown: The Definitive Guide - Yihui Xie, J. J. Allaire, Garrett Grolemund; https://bookdown.org/yihui/rmarkdown/ (free)\nWhat They Forgot to Teach You About R - Jenny Bryan, Jim Hester, Shannon Pileggi, E. David Aja; https://rstats.wtf/ (free)\nAdvanced R - Hadley Wickham, https://adv-r.hadley.nz/ (free)\nThe Seven Deadly Sins of Psychology: A Manifesto for Reforming the Culture of Scientific Practice - Chris Chambers (check it out from the library & give it a read when you can)\nImproving your Statistical Inferences - Daniël Lakens https://lakens.github.io/statistical_inferences/ (free)\nggplot2: Elegant Graphics for Data Analysis - Hadley Wickham, Danielle Navarro & Thomas Lin Pedersen https://ggplot2-book.org/ (free)",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "labs/lab-3_describe-viz.html",
    "href": "labs/lab-3_describe-viz.html",
    "title": "Lab 3: Describing and Visualizing Data",
    "section": "",
    "text": "Can’t believe we’re at Lab #3! Keep it going! We are going to continue to practice importing data and making a reproducible workflow. In this lab, you will be expanding the types of plots you are able to use.\nWe will be using data from the Bechdel test, a measure of the representation of women in fiction. You will be asked to do some Exploratory Data Analysis.\nHere are the things that you will need for this lab:\n\nDownload Lab 3 (.Rmd)\nDownload Bechdel Data (.csv)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the 🧶knitted .html file."
  },
  {
    "objectID": "labs/lab-3_describe-viz.html#instructions",
    "href": "labs/lab-3_describe-viz.html#instructions",
    "title": "Lab 3: Describing and Visualizing Data",
    "section": "",
    "text": "Can’t believe we’re at Lab #3! Keep it going! We are going to continue to practice importing data and making a reproducible workflow. In this lab, you will be expanding the types of plots you are able to use.\nWe will be using data from the Bechdel test, a measure of the representation of women in fiction. You will be asked to do some Exploratory Data Analysis.\nHere are the things that you will need for this lab:\n\nDownload Lab 3 (.Rmd)\nDownload Bechdel Data (.csv)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the 🧶knitted .html file."
  },
  {
    "objectID": "labs/lab-3_describe-viz.html#scenario-and-goal",
    "href": "labs/lab-3_describe-viz.html#scenario-and-goal",
    "title": "Lab 3: Describing and Visualizing Data",
    "section": "Scenario and Goal",
    "text": "Scenario and Goal\nIn this lab, you will act as a data journalist exploring a dataset on movies. We will use the data from the FiveThirtyEight story “The Dollar-And-Cents Case Against Hollywood’s Exclusion of Women.”\nThis analysis is about the Bechdel test, a measure of the representation of women in fiction.\nYour goal is to import, describe, and visualize this data to understand the characteristics of movies in the dataset and see if there are relationships between a movie’s budget, its box office gross, and its Bechdel Test rating. This is the critical first step in any analysis, known as Exploratory Data Analysis (EDA)."
  },
  {
    "objectID": "labs/lab-3_describe-viz.html#variables-of-interest",
    "href": "labs/lab-3_describe-viz.html#variables-of-interest",
    "title": "Lab 3: Describing and Visualizing Data",
    "section": "Variables of Interest",
    "text": "Variables of Interest\n\nyear: The year of movie release\nclean_test: Bechdel test result:\n\nok = passes test\ndubious\nmen = women only talk about men\nnotalk = women don’t talk to each other\nnowomen = fewer than two women\n\n\n\n\nbinary: Bechdel Test PASS vs FAIL binary\nbudget_2013: Total movie budget"
  },
  {
    "objectID": "labs/lab-3_describe-viz.html#exercises",
    "href": "labs/lab-3_describe-viz.html#exercises",
    "title": "Lab 3: Describing and Visualizing Data",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1: Importing and Inspecting\nFirst, you need to set up your RMarkdown to get it ready for importing the data and using the appropriate libraries. Be sure to have all libraries listed here in the first code chunk along with importing the data. I should not see any lines that say install.packages().\nI will attempt to reproduce your output in my own computer, so be sure that your code is reproducible.\nQuestion 1: Look at the output from your overview. How many total movies are in this database? And what year is the latest movie?\nYour Answer:\nQuestion 2: Calculate the Average budget of the whole dataset. Then, calculate the average for only movies in the year 2000.\nYour Answer:\n\n\n\nExercise 2: Grouped Descriptive Statistics\nAverages for the whole dataset are useful, but we are often more interested in comparing averages between groups. Let’s see if the average budget differs for movies that pass the Bechdel Test versus those that fail. The binary variable tells us this (“PASS” or “FAIL”).\nQuestion 3: Based on your summary table, do movies that pass or fail the Bechdel test have a higher average (mean) budget?\nYour Answer:\n\n\n\nExercise 3: Visualizing a Distribution (Histogram)\nLet’s visualize the distribution of domestic gross earnings (adjusted for 2013) across all the movies.\nQuestion 4: Describe the shape of the distribution you see in the histogram. Is it symmetric (like a bell curve), or is it skewed in one direction? Where do most movies’ earnings seem to be clustered?\nYour Answer:\n\n\n\nExercise 4: Examining the Bechdel Test distribution\nNow we want to see how many movies fall into each of the Bechdel categories. Generate a barplot of the clean_test variable to see what the distribution of the test is.\nThen choose a year in the dataset, create a similar plot (but only for that year). Therefore you should have 2 plots below:\nQuestion 5: Examine both charts and describe the similarities and differences that you are noticing.\nAnswer:\n\n\n\nExercise 5: Comparing Groups with a Boxplot\nNow let’s visually compare the inflation-adjusted international gross (intgross_2013) for movies that pass the Bechdel test versus those that fail. A boxplot is an excellent way to see differences in the median and spread between groups.\nQuestion 6: Look at the boxplot. The thick horizontal line in the middle of each box represents the median. Does there appear to be a large difference in the median domestic gross between movies that pass and fail the test?\nYour Answer:\n\nEnd of Lab 3. You’ve now practiced exploratory data analysis! It is always important to visualize your data to get a good sense of what you are working with. Don’t forget to Knit! 🧶"
  },
  {
    "objectID": "labs/lab-1_data-workflow.html",
    "href": "labs/lab-1_data-workflow.html",
    "title": "Lab 1: Foundations of a Data Workflow",
    "section": "",
    "text": "Welcome to your first lab! The goal of this assignment is to move beyond basic syntax and begin practicing a reproducible data analysis workflow.\nPlease complete the exercises below. Create a new .Rmd file and include the following at the top:\n---\ntitle: \"Lab 1: Foundations of a Data Workflow\"\nauthor: \"Your Name Here\"\ndate: \"`r Sys.Date()`\"\noutput: html_document\neditor_options: \n  chunk_output_type: console\n  markdown: \n    wrap: 72\n---\nYou should then be able to copy/paste everything below into your document.\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the final .html file.\n\n\n\nA major strength of R is its ecosystem of packages that add new functionality. We will use the tidyverse package in almost every analysis we do. The ggplot2 package, which is part of the tidyverse, contains a dataset called msleep about mammal sleep patterns.\n# Task 1: Load the tidyverse package.\n# Write your code here:\n\n\n# Task 2: The `msleep` dataset is available after loading the tidyverse.\n# Use the `glimpse()` function to get a quick overview of the `msleep` dataset.\n# Write your code here:\n\n\n# Task 3: Now use the `summary()` function on the `msleep` dataset.\n# Write your code here:\n❓Question 1: Based on the output of glimpse(), how many rows (observations) and columns (variables) are in the msleep dataset?\nYour Answer: [Type your answer here]\n❓Question 2: What is one key difference between the information provided by glimpse() and the information provided by summary() for a variable like sleep_total?\nYour Answer: [Type your answer here]\n\n\n\n\nLet’s say we are only interested in herbivores. We can use functions from the dplyr package (part of the tidyverse) to create a new, sorted dataset.\n# Task 1: Create a new object called `herbivores` that contains only the animals\n# from the `msleep` dataset where the `vore` column is equal to \"herbi\".\n# Hint: The syntax for filtering is: new_object &lt;- old_object %&gt;% filter(column_name == \"value\")\n# Write your code here:\n\n\n# Task 2: Now, sort this new `herbivores` dataset by total sleep time, from highest to lowest.\n# You can overwrite the `herbivores` object with the newly sorted version.\n# Hint: Use the `arrange()` function with `desc()` for descending order.\n# The syntax is: object &lt;- object %&gt;% arrange(desc(column_to_sort_by))\n# Write your code here:\n\n\n# Now, print the new, sorted `herbivores` object to see the result.\n❓Question: After sorting, which herbivore sleeps the most? How many hours does it sleep?\nYour Answer: [Type your answer here]\n\n\n\n\nData visualization is a critical part of understanding data. Let’s create a scatterplot to see if there is a relationship between how long a herbivore sleeps and how much time it spends dreaming.\n# Task: Create a scatterplot using ggplot().\n# We want to plot the `sleep_rem` (dreaming sleep) on the y-axis and `sleep_total` on the x-axis,\n# using only our `herbivores` dataset.\n# Fill in the blanks in the code below.\n\nggplot(data = ________, aes(x = _______, y = _________)) +\n  geom_????? +\n  labs(title = \"Total Sleep vs. REM Sleep in Herbivores\",\n       x = \"Total Sleep (hours)\",\n       y = \"REM Sleep (hours)\")\n❓Question 1: Look at the plot you created. In one or two sentences, describe the relationship you see between total sleep and REM sleep for these animals. Is the relationship positive, negative, or is there no clear relationship?\nYour Answer: [Type your answer here]\n❓Question 2: Are there any animals that seem unusual or stand out from the general pattern? Briefly describe one.\nYour Answer: [Type your answer here]\n\n\n\n\nOften, we want to calculate a single value to summarize our data. The summarise() function is perfect for this.\n# Task: Calculate the average (mean) total sleep time for ALL mammals in the original `msleep` dataset.\n# Hint: The syntax is: dataset %&gt;% summarise(new_variable_name = mean(column_name, na.rm = TRUE))\n# The `na.rm = TRUE` part is important because it tells R to ignore any missing values.\n# Write your code here:\n❓Question: What is the mean total sleep time for all mammals in the dataset?\nYour Answer: [Type your answer here]\n\nEnd of Lab 1. Don’t forget to Knit! 🧶"
  },
  {
    "objectID": "labs/lab-1_data-workflow.html#instructions",
    "href": "labs/lab-1_data-workflow.html#instructions",
    "title": "Lab 1: Foundations of a Data Workflow",
    "section": "",
    "text": "Welcome to your first lab! The goal of this assignment is to move beyond basic syntax and begin practicing a reproducible data analysis workflow.\nPlease complete the exercises below. Create a new .Rmd file and include the following at the top:\n---\ntitle: \"Lab 1: Foundations of a Data Workflow\"\nauthor: \"Your Name Here\"\ndate: \"`r Sys.Date()`\"\noutput: html_document\neditor_options: \n  chunk_output_type: console\n  markdown: \n    wrap: 72\n---\nYou should then be able to copy/paste everything below into your document.\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the final .html file.\n\n\n\nA major strength of R is its ecosystem of packages that add new functionality. We will use the tidyverse package in almost every analysis we do. The ggplot2 package, which is part of the tidyverse, contains a dataset called msleep about mammal sleep patterns.\n# Task 1: Load the tidyverse package.\n# Write your code here:\n\n\n# Task 2: The `msleep` dataset is available after loading the tidyverse.\n# Use the `glimpse()` function to get a quick overview of the `msleep` dataset.\n# Write your code here:\n\n\n# Task 3: Now use the `summary()` function on the `msleep` dataset.\n# Write your code here:\n❓Question 1: Based on the output of glimpse(), how many rows (observations) and columns (variables) are in the msleep dataset?\nYour Answer: [Type your answer here]\n❓Question 2: What is one key difference between the information provided by glimpse() and the information provided by summary() for a variable like sleep_total?\nYour Answer: [Type your answer here]\n\n\n\n\nLet’s say we are only interested in herbivores. We can use functions from the dplyr package (part of the tidyverse) to create a new, sorted dataset.\n# Task 1: Create a new object called `herbivores` that contains only the animals\n# from the `msleep` dataset where the `vore` column is equal to \"herbi\".\n# Hint: The syntax for filtering is: new_object &lt;- old_object %&gt;% filter(column_name == \"value\")\n# Write your code here:\n\n\n# Task 2: Now, sort this new `herbivores` dataset by total sleep time, from highest to lowest.\n# You can overwrite the `herbivores` object with the newly sorted version.\n# Hint: Use the `arrange()` function with `desc()` for descending order.\n# The syntax is: object &lt;- object %&gt;% arrange(desc(column_to_sort_by))\n# Write your code here:\n\n\n# Now, print the new, sorted `herbivores` object to see the result.\n❓Question: After sorting, which herbivore sleeps the most? How many hours does it sleep?\nYour Answer: [Type your answer here]\n\n\n\n\nData visualization is a critical part of understanding data. Let’s create a scatterplot to see if there is a relationship between how long a herbivore sleeps and how much time it spends dreaming.\n# Task: Create a scatterplot using ggplot().\n# We want to plot the `sleep_rem` (dreaming sleep) on the y-axis and `sleep_total` on the x-axis,\n# using only our `herbivores` dataset.\n# Fill in the blanks in the code below.\n\nggplot(data = ________, aes(x = _______, y = _________)) +\n  geom_????? +\n  labs(title = \"Total Sleep vs. REM Sleep in Herbivores\",\n       x = \"Total Sleep (hours)\",\n       y = \"REM Sleep (hours)\")\n❓Question 1: Look at the plot you created. In one or two sentences, describe the relationship you see between total sleep and REM sleep for these animals. Is the relationship positive, negative, or is there no clear relationship?\nYour Answer: [Type your answer here]\n❓Question 2: Are there any animals that seem unusual or stand out from the general pattern? Briefly describe one.\nYour Answer: [Type your answer here]\n\n\n\n\nOften, we want to calculate a single value to summarize our data. The summarise() function is perfect for this.\n# Task: Calculate the average (mean) total sleep time for ALL mammals in the original `msleep` dataset.\n# Hint: The syntax is: dataset %&gt;% summarise(new_variable_name = mean(column_name, na.rm = TRUE))\n# The `na.rm = TRUE` part is important because it tells R to ignore any missing values.\n# Write your code here:\n❓Question: What is the mean total sleep time for all mammals in the dataset?\nYour Answer: [Type your answer here]\n\nEnd of Lab 1. Don’t forget to Knit! 🧶"
  },
  {
    "objectID": "slides/wrangle.html#naming-conventions",
    "href": "slides/wrangle.html#naming-conventions",
    "title": "dplyr: Wrangling",
    "section": "Naming Conventions",
    "text": "Naming Conventions\nWe could use the rename() function, but that take a lot of work. It can be helpful if you want to change it to something specific, but we may just want to make these names a little cleaner."
  },
  {
    "objectID": "slides/wrangle.html#using-select",
    "href": "slides/wrangle.html#using-select",
    "title": "dplyr: Wrangling",
    "section": "Using select()",
    "text": "Using select()\nYou used this in lab, so you are all experts. Let’s review by looking at the cheatsheet for dplyr.\nThe dplyr package makes data wrangling and transformation much easier. select() allows you to…well…select the columns that you want to keep.\n\nCreate a dataset that only includes: id, progress, duration, sex, age, TIPI items and the sleep items"
  },
  {
    "objectID": "slides/wrangle.html#using-select-1",
    "href": "slides/wrangle.html#using-select-1",
    "title": "dplyr: Wrangling",
    "section": "Using select()",
    "text": "Using select()\n\ntipi &lt;- tipi %&gt;% \n  select(c(id, progress, duration_in_seconds,  sex, age, \n           sleep_quality, hours_of_sleep, tipi_1, \n           tipi_2, tipi_3, tipi_4, tipi_5, tipi_6, tipi_7, \n           tipi_8, tipi_9, tipi_10))\n\ntipi &lt;- tipi %&gt;% \n  select(c(id:duration_in_seconds, sex, age, sleep_quality, \n           hours_of_sleep, contains(\"tipi_\")))\n\n## OR\n\ntipi &lt;- tipi %&gt;% \n  select(-c(consent:genderid_7_text, year_school:q85_6_text, \n            sleep_quality, hours_of_sleep))"
  },
  {
    "objectID": "slides/wrangle.html#extract-rows",
    "href": "slides/wrangle.html#extract-rows",
    "title": "dplyr: Wrangling",
    "section": "Extract Rows",
    "text": "Extract Rows\nThe ‘filter()’ function is used to subset observations based on their values.\nThe result of filtering is a data frame with the same number of columns as before but fewer rows.\nThe first argument is data and subsequent arguments are logical expressions that tell you which observations to retain in the data frame.\nNote: You are stating which types of rows you want to keep. If a variable can answer TRUE to your condition, then it will stay in the data.\n\nfilter(starwars, hair_color == \"none\")\n\n# A tibble: 38 × 14\n   name     height  mass hair_color skin_color eye_color birth_year sex   gender\n   &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n 1 Darth V…    202   136 none       white      yellow          41.9 male  mascu…\n 2 IG-88       200   140 none       metal      red             15   none  mascu…\n 3 Bossk       190   113 none       green      red             53   male  mascu…\n 4 Lobot       175    79 none       light      blue            37   male  mascu…\n 5 Ackbar      180    83 none       brown mot… orange          41   male  mascu…\n 6 Nien Nu…    160    68 none       grey       black           NA   male  mascu…\n 7 Nute Gu…    191    90 none       mottled g… red             NA   male  mascu…\n 8 Jar Jar…    196    66 none       orange     orange          52   male  mascu…\n 9 Roos Ta…    224    82 none       grey       orange          NA   male  mascu…\n10 Rugor N…    206    NA none       green      orange          NA   male  mascu…\n# ℹ 28 more rows\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;"
  },
  {
    "objectID": "slides/wrangle.html#filter-observations",
    "href": "slides/wrangle.html#filter-observations",
    "title": "dplyr: Wrangling",
    "section": "Filter Observations",
    "text": "Filter Observations\nWe can now generate a subset of observations based on a particular value\nThere may be some data checks that you perform when wrangling data. One that I would suggest is to look at the overall completion percentages and the amount of time that it took for participants to complete the questionnaire.\nThis is exactly what filter() is set to do.\n\n# Assigning it to a new variable\nclean_tipi_data &lt;- tipi %&gt;% \n  filter(progress == 100 & \n         duration_in_seconds &gt; 600)"
  },
  {
    "objectID": "slides/wrangle.html#compute-new-variable",
    "href": "slides/wrangle.html#compute-new-variable",
    "title": "dplyr: Wrangling",
    "section": "Compute new variable",
    "text": "Compute new variable\nWe often need to make a sum/mean score for a variable of interest, or transform it in some way.\nThe mutate() function is most commonly used to add new columns to your data frame that are functions of existing columns.\nmutate() requires data as its first argument, followed by a set of expressions defining new columns.\n\nNote: New variables are automatically added at the end of the data frame (scroll to the right to see them)\n\nFor example, we have the Ten Item Personality Inventory\nTake a look at the scoring of the TIPI and compute the necessary variables for all subscales"
  },
  {
    "objectID": "slides/wrangle.html#sum-scores",
    "href": "slides/wrangle.html#sum-scores",
    "title": "dplyr: Wrangling",
    "section": "Sum Scores",
    "text": "Sum Scores\nAnd finally, we can use mutate() to create total scores (or really any type of computation)\nFor the TIPI data, we need to compute each of the 5 pieces of the Big Five (Extraversion, Agreeableness, Conscientiousness, Emotional Stability and Openness to Experience)\n\nfinal_tipi &lt;- wizard_tipi_data %&gt;% \n  mutate(\n    extra = (tipi_1 + tipi_6r)/2,\n    agree = (tipi_2r + tipi_7)/2,\n    consc = (tipi_3 + tipi_8r)/2,\n    emo = (tipi_4r + tipi_9)/2,\n    open = (tipi_5 + tipi_10r)/2\n  )"
  },
  {
    "objectID": "slides/wrangle.html#export",
    "href": "slides/wrangle.html#export",
    "title": "dplyr: Wrangling",
    "section": "export()",
    "text": "export()\nNow that we have a scored dataset, we will want to save that.\nYou can do this by re-running all of your steps above, or by exporting your dataset.\nexport(final_tipi, here(\"files\", \"data\", \"final_tipi.csv\"))\n\n\n\n\n\n\nNote\n\n\nBe careful when exporting and knitting docs. Each time you knit, it will run the export code. After I export, I usually will comment out that line of code."
  }
]